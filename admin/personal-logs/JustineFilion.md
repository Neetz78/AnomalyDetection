# Work Log for Justine Filion

| Day   | Hours | Description                              |
|-------|-------|------------------------------------------|
| May 01 | X     |                                          |
| May 02 | X     |                                          |
| May 03 | 8     | <ul><li>Attended class where the format of the class was introduced.</li><li>Had a 2 hour meeting with our client to discuss the project.</li><li>Had a 2 hour meeting with the group to complete the team contract, the code of conduct and the team charter canvas provided by the client.</li><li>Set up the trello board and made a list of what we had to complete. Added all the upcoming meetings to the common calendar.</li><li>Explored the data and documentation that was given to us for approximately 2 hours.</li></ul>                                 |
| May 04 | 9    |  <ul><li> Had a 30 minute meeting with Aditya to go over the questions we had from the previous day.</li><li>Right after, we had another 30 minute meeting with the team to discuss the next steps.</li><li> Spent the following 2 hours, looking at documentation on time series clustering.</li><li> Had another 30 minute meeting with the team after lunch to discuss the proposal and how to split the workload.</li><li>Spent from 2 to 7 trying to clarify the scope of the project by researching further information on anomaly detection and writing the first draft of our timeline for the proposal.</li>                                        |
| May 05 | 9     |  <ul><li>Had a 1 hour meeting with Aditya and Levannia to address the questions we had about how to approach the unsupervised techniques and others</li><li>Wrote the minutes for the meeting, which led me to do some research to fill some gaps in my understanding (2 hours)</li><li>Completed the deliverable, schedule and responsabilities section (2 hours)</li><li>Had a meeting with Neethu where we wrote the 'Aims and objectives' section of the proposal (2 hours)</li><li>Started working on the powerpoint presentation for our meeting with the advisory commitee and finished the formatting of the proposal (2 hours)</li>                                       |
| May 06 | 6     |  <ul><li>Had a 15 minute meeting with the team before the meeting with the client (20 minutes), followed by another team meeting after (15 minutes).</li><li>Worked on the powerpoint presentations (for advisory committee and capstone advisors) for the next 5 hours.</li>                                          |
| May 08 | 3     | <ul><li>Spent approximately 2 hours reading literature on imbalanced datasets</li><li>Spent 30 minutes practicing and modifying slides for the advisory committee presentation</li><li>Spent 30 minutes practicing presentation with all team members</li>                                        |
| May 09 |  8    |  <ul><li> Spent the first 2 hours of the morning continuing to read on imbalanced datasets (Synthetic Minority Oversampling Technique, Tomek links, Sample subset optimization)</li><li> Had a 45 minutes meeting with the team to go over the slides and practice for our 2 presentations (advisory committee and MDS check-in)<\li><li> Had out first advisory committee that lasted app. 45 minutes followed by a 15 min team debrief </li> Spent 1 hour trying to help Sara find the discrepancies between the time series data and the predictor data (to make sure the same IDs were in both with no duplicates) </li><li> Spent another 2 hours reading various research paper looking at different pipelines to deal with imbalanced data (i.e. combine over and undersampling, combine SMOTE + tomek links, condensed nearest neighbor rule with tomek links = one-sided selection)</li><li> Looked into how to set up virtual environments and include a .gitignore file in the repo (also decided how to deal with the requirements.txt file (45 minutes)</li><li> (30 minutes) Wrote the minutes for the MDS check-in meeting and read a paper on anomaly detection in ECG waveforms</li>                                      |
| May 10 | 8     | <ul><li> Met with the team a couple of times throughout the day to try and organize ourselves better (1 hour)</li><li> Researched different statistical tests we could use to obtain a representative sample from the successful readings (to decrease imbalanced dataset --> maybe go from 400 000 successful readings to 10 000) (4 hours).</li><li> Spent 2 hours implementing the two-sample Kolmogorov-Smirnov Test for our aggreagare predictors data to compares samples (the subset vs total readings) to see if their distribution matched.</li><li> Spent 1 hour creating my virtual environment and trying to understand why the version of the packages that I installed did not correspond to those in my requirements.txt file.                                          |
| May 11 | 8    |  <ul><li> Had a meeting with the team to discuss the progress we made yesterday and what we planned on doing today (1 hour)</li><li> Spent 3 hours reading a review paper on what has been done from 2005-2015 in terms of time-series clustering. This led me to do a lot of other research on various techniques/vocabulary I was not familiar with</li><li>Read various litterature on algorithms used on clustering of time series with big data (most of the research I had seen used small datasets. With over 400 000 timeseries, calculating distance matrices using dynamic time warping, for example, is inconceivable. We need to find a way to either decrease our sample size or find different algorithms) (2 hours)</li><li> Looked into oversampling techniques specific to timeseries data, because we will have to find a way to increase or 80 pin contact errors somehow - still don't have a clear idea on how to do it (1 hour)</li><li>Tried to get a better understanding of filtering and Fourier transformation (sara + 3blue1brown videos).(1 hour)</li>                                           |
| May 12 | 7    | <ul><li> Read various papers to find a way to sample a subset of the successful readings..again (and still found no research where they used a similar technique). I was able to make an important distinction in the kind of sampling that I do want, and found that most paper talk about sequence sampling (oversampling and undersampling) which refers to sampling within a specific time sample. This is not what we want. Instead, we want to artificially make new complete timeseries that mimic pin contact errors. I don't think this will work. (2 hour) </li><li> Continued to read more about bootstrapping and how it could possibly help us with our imbalanced data. Found no literature where they used a similar approach to ensemble classification but this time for clustering (i.e bagging or random forest where we apply the same algorithm to different data and aggregate the results). I found somehting that seemed similar (consensus clustering), but here, they use the clusters obtainedfrom various different models applied to the same data and come up with the best clustering. This will not work in our case, we need the same algorithm applied to different data (2 hours).</li><li> Spent 1 hour making a big review of what I have researched, what I have tried and what i think will work and not work (mainly no work, still have not found a solution).</li><li>Read excerpts from a PhD thesis on whole timeseries clustering. There was a lot of different algorithms/pipelines used and they specified the difference between a feature based approaches versus shape-based. We may potentially want to split the teams so that 2 memebers look at each approach, versus using the predictor file.(1 hour) </li><li> Spent 1 hour in total in team meetings (30 minutes this morning to catch-up and 30 minutes at the end of the day to go over what we want to present during tomorrows meeting with Siemens)</li>.                                          |
| May 13 | 6.5  | <ul><li>Met with the client to discuss about the progress that was made this week (1 hour)</li><li>Met with the group to discuss next steps (30 mins)</li><li>Made the presentation for next weeks meeting with our capstone adviser (1 hour)</li><li> Redownloaded all the data files (new files received from client) and ran Sara's script to standardize them. Organized my folders for the project. (1 hour)</li><li>Had a 20 minute meeting with Irene to discuss clustering interrogations</li><li>Started writing a function to perform random sampling from our data to be used for undersampling (1.5 hours).</li><li>Met with Jeff to discuss clustering interrogations (1 hour).</li>                                          |
| May 14 | 1     | <ul><li>Calculated features using the tsfresh python package</li></ul>                                        |
| May 15 | 1     | <ul><li>Discussed with Sara what had to be adressed in Mondays meeting with Siemens. Went over the assumptions of DTW and discussed why we don't think it is an appropriate measure.</li></ul>                                         |
| May 16 | 9    | <ul><li>Had a meeting to go over what Sara and I had planned on saying to Siemens with the others. They were good with it and had nothing to add.(15 minutes)</li><li>Had a meeting with Siemens to go over what we had planned for this week (30 minutes)</li><li>Had another team meeting to discuss plans for the day (15 min).</li><li> Used the features that I had calculated Saturday to try and do some clustering. (2 hours). Obtained very poor results.</li><li>Read some literature of different features to extract from timeseries. Read more on Fourier transforms. (1 hour).</li><li>Found the `extract_features` function in the tsfresh package that calculates app. 600 features for timeseries (much more than I had done on Saturday, manually). Had to wrangle the data in a format that could be used by the function.Also applied the `select_features` function to filter the features according to which ones were most relevant to classify pin contact and unsuccessful (2.5 hours).</li><li>Scaled the features and applied hierarchical clustering. Found the confusion matrix. Results arent good. (1.5 hours).</li><li> Worked on the presentation for tomorrows meeting (1 hour).</li>                                          |
| May 17 | 6.5     | <ul><li>Fixed the slides and practiced my part(30 min).</li><li>Meeting with team to go over presentation for today (15 min)</li><li> Cleaned the git repo (15 min)</li><li>Had to standardize data (after modification in script). Debugged an error with the script.(30 min)</li><li>Windowed the data with the new standardized data (30 min)</li><li> Meeting with Irene and Debangsha (30 min)</li><li>Downloaded new synthetic pin contact errors, standardized and windowed (30 minutes)</li><li>Wrote a function that creates features matrices from the windowed data (30 min).</li><li>Performed PCA on the feature matrix obtained from the calibration window. Plotted the first and second component and obtained results that were promising. There seemed to be 2 groups of pin contact errors, ones with low scores on PC1 and PC2 and the other with high scores on PC1. Had to go over PCA notes to understand difference between scores and loadings. Created scree plot and cumulative proportion of variance to choose number of components to keep. (2.5 hours)</li><li> Used hierarchical clustering on the first 5 principal components. Did not get good results.(30 minutes)</li></ul>|
| May 18 | 9    | <ul><li> Had a meeting with the team to discuss what we did yesterday. (30 min)</li><li>Continued working on clustering PCA components obtained from the features on the calibration window. Did not get good results. (30 minute)</li><li> Applied the same PCA technique to the post window (1.5 hour).</li><li> Had a meeting with Debangsha. We discussed potential ideas (20 minutes). </li><li> Found that using the post window, if I used a multi-step clustering approach on the principal components, I get VERY good results! Spent all day trying to make sure there was no bug in my code and that the good results weren't a fluke. Cleaned my notebook so that'd be easier to present to the other teamates tomorrow. (6 hours)</li><ul>                                         |
| May 19 | 9   | <ul><li> Had a meeting with the team (30 minutes). </li> <li>Continued working on the clustering from yesterday and found a coding error that resulted in me losing all the good results :(. I thus had to start from scratch and go back to look at each window individually and see if I could find any clusters. I did not. (5 hours)</li><li> Went back and windowed the data before scaling thinking maybe that scaling first removes important information that could be useful for the clustering (2 hours).</li><li>Had a meeting with the team to discuss tomorrow's meeting with the client and worked on the powerpoint slides (1h30).</li></ul>                                      |
| May 20  | 5   | <ul><li> Had a meeting witht the team to go over the slides for our meeting with Siemens (30 min).</li><li>Had a meeting with Siemens where we discussed what we did this week. We got a lot of feedback and some good ideas on what to explore next (1 hour).</li><li> Wrote the weekly update (15 min).</li><li> Debugged why my feature extraction function wasn't working on the data that had been windowed and then standardized. Windowing first results in a std that is very close to 0 in the calibration window and so the standardized waveforms explode (divide by very small number) (1.5 hour)</li><li> After discussing with Levannia, she mentionned that standardizing the calibration might not be necessary because the same fluid type is used. Also, calibration period is where most of the pin contacts occur. Tried extracting features from unstandardized waveforms for calibration window and then clustering. No significant results were obtained. Also, increase the number of clusters to 31 (which equates to the number of different returncode (after suggestion from Levannia) (2 hour)                                      |
| May 23  |  8   | <ul><li>Meeting with the team (15 min)</li><li>Created plan for directory so that everyone has the same structure and paths (15 min)</li><li>Created 3d plot to visualize the principal components differently (1.5 hours)</li><li>Made sure that all notebooks (for each window) contained the updated version of the feature extraction function. Cleaned up all the notebooks and kept only the ones that were useful. Changed the format of the dataframe returned by the feature_matrix  function (2 hours)</li><li>Working on presentation slides for tomorrow (20 min)</li><li>Worked on creating a template for the tsfresh feature extraction - clustering pipeline to include in the github (2 hours)</li><li> Meeting with the team to go over the 3 presentations we have tomorrow (2 hours)</li> |
| May 24 |  9  | <ul><li> Had a meeting with Siemens (1h20min)</li><li> Went over the slides for the presentation with Irene (40 min)</li><li>Meeting with Irene and Debangsha (30 min)</li><li>Wrote the minutes for the meeting (30 min) </li><li> Had the advisory comittee meeting (1 hour)</li><li>Had an impromptu meeting with Levannia and Aditya to go over some suggestions they had (30 min)</li><li> Sent some files to Levannia so that she could give us data on a 'target' analyte (20 min).</li><li>Had a meeting with the team members to organize ourselves (next steps) (40 mins).</li><li> Wrote the minutes for the impromptu meeting (30 min)</li><li>Finished the notebook to give Siemens for the tsfresh pipeline (3 hours) </li>                                      |
| May 25 |  8   | <ul><li> Read on the different types of filtering (more specifically Savitzky–Golay filter and median filter) and played with them and their parameters in python to see the effect they had on our waveforms. Compared the filtered waveforms to our target analyte (that is less noisy then ours) to determine how much noise to remove. Found it difficult to compare them as they are on very different scales. Read into possible ways to determine the optimal parameters instead. (3.5 hours).</li><li> Had a meeting with the team to talk about the different filtering technique we had looked at. (1 hour).</li><li> Continued exploring the waveforms and decided to just try a very simple rolling average for now and see what kind of results we get from that. Built 2 python functions, 1 that plots the rolling mean overtop the raw data and the other, that create the rolling average dataframe. (3.5 hours).                                       |
| May 26  |  9   | <ul><li> Built a function that splits the moving average dataframe into different windows. Ran into various issues with indexing that took forever to debug. (4 hours).</li> Had a meeting with the girls to talk about what we were working on. (1 hour) </li><li> Plotted various graphs (including estimation of power spectral density using discrete fourrier transforms) for different windows to see how the moving average smoothing filter looked compared to our target analyte that is less noisy (2 hours)</li><li> Researched spectral density, fourrier transforms and frequency to gain a better understanding of these concepts (1 hour).</li><li> Had a conversation with Sara where we explained to each other what we understood from the theory and our interpretation of the graphs we obtained. By doing so, we were able to solidify our understanding and be more confident in the validity of our process. We also put together a proof of concept demonstration to show our client tomorrow. (1 hour)</li>                                   |
| May 27  | 6  | <ul><li> Met with the team to discuss what we wanted to address in the client meeting and make sure we were all on the same page (30 min)</li><li> Met with our client to give them an update on the progess that we made with filtering (30 min)</li><li>Continued working on my windowing function to make it do what I wanted it to (2 hours)</li><li> Worked on the slides for the midterm presentation (3 hours).                                       |
| May 29  | 4    | <ul><li> Finished the slides for the midterm presentation ( 2 hour)</li><li> Practiced the slides (2 hours)</li>                                      |
| May 30  | 11.5 | <ul><li> Practiced the presentation for the data review committee (30 mins).</li><li> Worked on debugging the windowing function (1 hour)</li><li>Presented during the data review committee (30 mins)</li><li>Practiced for the midterm presentation (4 hours)</li><li> Continued debugging the windowing function (finally got it to work) and started calculating various metrics on the different windows (of the moving average). The plan is to find differences in metrics (i.e. the difference between the mean in the sample window and the mean in the post window) hoping it will yield better results.(5.5 hours)</li>.|  
| May 31  | 8 | <ul><li> Practiced the midterm presentation (30 mins).</li><li> Attended the midterm presentations (3.5 hours)</li><li> Performed clustering on the differences in mean between the different windows and summarized/caracterized the waveforms using visualizations as well as info from the predictor file. Tried using randomforest using the differences in mean just to see if they were decent predictors, and they do yield a recall of  app. 63% and a F1 score of app. 70% which is not bad. Could be a potentially good idea to include these features in the clustering that Sara did with the raw waveforms (4 hours).| 
| ----- | ----- | -------------- End of May -------------- |
| Jun 01 | 8     | <ul><li> Prepped for the meeting with our client (30 min)</li><li> Had a meeting with the client (1 hour)</li><li>Found that when including the wet-up period before normalizing, the results in the difference of means between the windows was significantly different. Spent a long time trying to understanding the root cause, with not much success. (3 hours).</li><li> Used convolution instead of moving average and found the difference in mean for each window (1 hour)</li><li> Started looking at different clustering we could use (kshape in the tslearn package. Started reading the research paper describing the algorithm (uses cross correlation as a distance metric and calculates medoids) (2.5 hours)</li></ul>                                         |
| Jun 02 | 8     | <ul><li> Had a meeting with the team (30 min)</li><li> Performed clustering using KShape. Implemented various different pipelines (only timeseries, timeseries with predictors, PCA on timeseries and predictors without, PCA on timeseries and predictors). Found a very promising pipeline but I am worried about how we scaled the data in the preprocessing of it. We scaled according to the rows that conatained time series data and predictors, concerned about the effect on the mean and variance. Also plotted the medoids of the clusters to get the mean/prototype shape of each clusters formed. (7.5 hours)</li></ul>                                        |
| Jun 03 | 9   | <ul><li> Weekly check-in with the client (30 min)</li><li> Meeting with the team to discuss the progress we've made (30 min)</li><li> Wrote the minutes for the meeting (15 mins)</li><li> Cleaned up my notebook with the kshape algorithm and extracted the TestIds that we wanted to get verified by Levannia (3 hours)</li><li> Debugged the function the output the diagnostic plot (1 hour)</li><li>Started working on the presentation for the advisory committee meeting on Monday (2 hours)</li><li> Used the functions that Sara created to describe the clusters. Took me a while to figure out what format the df had to be in in order to input them as arguments to the function. Changed the font of the axis and title just to make them more readable so that I could take screenshot of them for the presentation (2 hours)</li>                                     |
| Jun 04 | 2     |<ul><li> Read more into Kshape and understood the similarity measure they are using. It is sooo interesting! They use a normalized version of cross correlation and a centroid based approach.</li> Continued working on the slides for the advisory committee meeting (added slides on cross correlation) and tried performing kshape clustering without normalizing the timeseries first. It was very ineffective and the clusters were atrocious! By reading the paper on Kshape I was able to understand why this is the case (2 hour)</li>                                         |
| Jun 05 | 3    |<ul><li> Completed the slides for the advisory committee (2 hours)</li>                                          |
| Jun 06 | 8     | <ul><li>Had a meeting with the team to practice the presentation for the advisory committee (30 mins)</li><li> Worked on cleaning the Kshape notebook. Documented all the attemps we tried and why the failed (1.5 hours)</li><li>Had the advisory committee meeting (30 mins)</li><li> Went over the slides for tomorrows meeting with our capstone advisor, modified some of the slides (1 hour)</li><li> Continued cleaning the KShape notebook (this included importing and using the diagnostic functions from the script Sara made, as well as writing my own function to plot the centroids against their respective cluster). Also reran the KShape algorithm but this time with n_init = 10 (which runs the algo 10 times with different seeds and outputs the one with the lowest inertia --> was a lot longer to run) (4.5 hours)</li></ul>
| Jun 07 | 8     | <ul><li> Worked on coding a function that plotted the centroid of each cluster. Because we are using predictors and timeseries data, the centroid can't be plotted with respect to time anymore (we get weird distortions). Took me a while to figure that out. Once I did, I decided to run KShape only with the timeseries data and give the client that pipeline so that they could plot the centroid (and it mean something). Finished up cleaning the KShape notebook. (5 hours)</li><li>Had a meeting with the team to go over the slides (10 minutes)</li><li>Had weekly update meeting with Irene (20 min)</li><li>In the process of reviewing the notebooks Sara worked on and making sure there is no confidential information in the comments. Making sure everything runs smoothly. Also set up a folder on my local machine with the same structure as there will be on the cloud and changing all the paths to fit that structure.(2.5 hours)</li></ul>                                        |
| Jun 08 |  8  |<ul><li> Peer reviewed the autoencoder notebook, added comments, changed variable names so they were more descriptive, found a small error and fixed it. (4 hours)</li><li> Changed the paths and updated the requirements.txt file for all of the notebooks. (3 hours)</li><li> Added the notebooks I made for iteration 1 to the archive folder and updated the glossary (1 hour)</li></ul> 
| Jun 09 |  5  |<ul><li> Added Saisrees archive notebooks and glossary to the final structure. Emailed the client with the requirements.txt file. Downloaded the presentations to their cloud as well as the final folder containing all of our code and data (30 mins)</li><li> Had a meeting with the team to discuss next steps (15 min)</li><li>Brainstormed how we should format the final report with Sara (included making flow charts) (30 min)</li><li>Built a summary table detailing all of our attempts (3.75 hours)</li>
| Jun 10 |  4  |<ul><li> Had a meeting with the client to go voer our file structure and the skeleton for our final report (1 hour)</li><li> Worked on the intro for the methodology section of the final report (3 hours)</li>
| Jun 13 |  9  |<ul><li> Worked on the final report (PCA section, explaining cross-correlation, completing table with various pipelines, rereading background and other sections) (8.75 hours)</li><li> Completed the weekly update (15 mins)</li>|
| Jun 14 |  9  |<ul><li> Prepared and presented our weekly update (1 hour)</li><li>Worked on the final report (TSFresh, KMeans, KShape) (8 hours)</li>|
| Jun 15 |  11  |<ul><li> Worked on the final report (edited lots of sections, decided how we wanted to format the methods section and what to put in the results, starting cleaning the report and making appendices, starting describing the pipelines)</li>|
| Jun 16 |  12  |<ul><li> Worked on the final report (methods section, executive summary, future steps and edited the whole thing)</li>|
| ----- | ----- | -------------- End of June ------------- |

