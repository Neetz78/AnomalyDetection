{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9139037-4ebb-476c-bfab-824b4e021cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf83061f-745d-4c16-8b88-b1069e40acec",
   "metadata": {},
   "source": [
    "## Wet-up removed (-30, 40) --> Normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0c8399-a146-4baf-9324-ce68fcaae1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timeseries\n",
    "# We use the normalized data without the wet up period (from -30 to 40), and then apply the moving average\n",
    "ecd_norm = pd.read_csv(\"../../../data/TimeSeriesData/Normalized/ecd_norm_window.csv\")\n",
    "ecd_syn_norm = pd.read_csv(\"../../../data/TimeSeriesData/Normalized/syn_norm_window.csv\")\n",
    "ecd_con_norm = pd.read_csv(\"../../../data/TimeSeriesData/Normalized/cont_norm_window.csv\")\n",
    "\n",
    "ecd_tot_norm = pd.concat([ecd_norm, ecd_syn_norm, ecd_con_norm], axis = 0)\n",
    "un_norm = pd.read_csv(\"../../../data/TimeSeriesData/Normalized/un_norm_window.csv\")\n",
    "\n",
    "\n",
    "# Predictors\n",
    "un_pred = pd.read_csv('../../../data/RawDataPredictors/New/Unsuccessful.csv')\n",
    "ecd_pred = pd.read_csv('../../../data/RawDataPredictors/New/ECDContact.csv')\n",
    "syn_pred = pd.read_csv('../../../data/RawDataPredictors/New/SyntheticPC.csv')\n",
    "con_pred = pd.read_csv('../../../data/RawDataPredictors/New/PCAggContaminated.csv')\n",
    "\n",
    "ecd_pred_tot = pd.concat([ecd_pred, syn_pred, con_pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18e5597-c795-4be8-bb8d-4259c0ff9f79",
   "metadata": {},
   "source": [
    "## Normalized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8ca300-8ac1-4293-804d-3c0219bf44e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timeseries\n",
    "# We use the normalized data without the wet up period (from -30 to 40), and then apply the moving average\n",
    "ecd_norm = pd.read_csv(\"../../../data/TimeSeriesData/Normalized/ecd_norm.csv\")\n",
    "ecd_syn_norm = pd.read_csv(\"../../../data/TimeSeriesData/Normalized/syn_norm.csv\")\n",
    "ecd_con_norm = pd.read_csv(\"../../../data/TimeSeriesData/Normalized/cont_norm.csv\")\n",
    "\n",
    "ecd_tot_norm = pd.concat([ecd_norm, ecd_syn_norm, ecd_con_norm], axis = 0)\n",
    "un_norm = pd.read_csv(\"../../../data/TimeSeriesData/Normalized/un_norm.csv\")\n",
    "\n",
    "\n",
    "# Predictors\n",
    "un_pred = pd.read_csv('../../../data/RawDataPredictors/New/Unsuccessful.csv')\n",
    "ecd_pred = pd.read_csv('../../../data/RawDataPredictors/New/ECDContact.csv')\n",
    "syn_pred = pd.read_csv('../../../data/RawDataPredictors/New/SyntheticPC.csv')\n",
    "con_pred = pd.read_csv('../../../data/RawDataPredictors/New/PCAggContaminated.csv')\n",
    "\n",
    "ecd_pred_tot = pd.concat([ecd_pred, syn_pred, con_pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba3accc-2bd5-4c9f-a50d-2438d83c3c8a",
   "metadata": {},
   "source": [
    "## Wet-up removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db72617f-673a-4708-a9d2-a4f0d0f413cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timeseries\n",
    "# We use the normalized data without the wet up period (from -30 to 40), and then apply the moving average\n",
    "ECD = pd.read_csv(\"../../../data/TimeSeriesData/Windowed/ECD.csv\")\n",
    "ecd_syn = pd.read_csv(\"../../../data/TimeSeriesData/Windowed/syn.csv\")\n",
    "ecd_con = pd.read_csv(\"../../../data/TimeSeriesData/Windowed/cont.csv\")\n",
    "\n",
    "ecd_tot = pd.concat([ECD, ecd_syn, ecd_con], axis = 0)\n",
    "un = pd.read_csv(\"../../../data/TimeSeriesData/Windowed/un.csv\")\n",
    "\n",
    "\n",
    "# Predictors\n",
    "un_pred = pd.read_csv('../../../data/RawDataPredictors/New/Unsuccessful.csv')\n",
    "ecd_pred = pd.read_csv('../../../data/RawDataPredictors/New/ECDContact.csv')\n",
    "syn_pred = pd.read_csv('../../../data/RawDataPredictors/New/SyntheticPC.csv')\n",
    "con_pred = pd.read_csv('../../../data/RawDataPredictors/New/PCAggContaminated.csv')\n",
    "\n",
    "ecd_pred_tot = pd.concat([ecd_pred, syn_pred, con_pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc281586-8515-4fc7-9c50-9db3b56ad353",
   "metadata": {},
   "source": [
    "## Creating Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d93a8a-bd26-4a96-8302-253080b99594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_moving_average_data(data, window, center = True):\n",
    "    rolling_data = data.drop(columns = 'TestId').rolling(window, axis = 1, center = center).mean().dropna(axis = 1, how = 'all').reset_index(drop = True)\n",
    "    rolling_data['TestId'] = data['TestId'].reset_index(drop = True)\n",
    "    rolling_data = rolling_data.dropna(axis = 0, thresh = 2).reset_index(drop = True) # For series that are smaller than window\n",
    "    return rolling_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5151fe7b-70a8-4aa7-bb28-1b7c7ddfdf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecd_MA = creating_moving_average_data(ecd_tot_norm, 31)\n",
    "un_MA = creating_moving_average_data(un_norm, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf51d9f9-4a97-4087-b9ce-34c625c179e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecd_MA_w = creating_moving_average_data(ecd_tot, 31)\n",
    "un_MA_w = creating_moving_average_data(un, 31)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a315729c-a5b7-44a9-9db5-38c531bf9b3a",
   "metadata": {},
   "source": [
    "## Creating Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae81914b-7191-495d-8c4e-484db4d07823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window(start, end, ts, pred, window, center = True):\n",
    "    \"\"\"Windows the data output by the `creating_moving_average_data` function. \n",
    "\n",
    "    Args:\n",
    "        start (int): Start of window with respect to sample detect time (i.e -15 represents 15 seconds before sample detect)\n",
    "        end (int): End of window with respect to sample detect time (i.e 30 represents 30 seconds after sample detect)\n",
    "        ts (pandas data frame): Output from the `creating_moving_average` function (a dataframe containing the moving averages). \n",
    "        pred (pandas data frame): Dataframe containg the predictor file containing a column with the SampleDetectTime (i.e when windowing the unsuccessful readings, use the predictor file for the unsuccessul readings).\n",
    "        window (int): The window that was used when calculating the moving average for the ts dataframe (needs to be an odd number if centered).\n",
    "        center (bool, default = True): Whether or not the moving average that was calculated for the ts dataframe was centered (True) or not(False).\n",
    "\n",
    "    Returns:\n",
    "        A new pandas data frame with z-normalized time series stored in the rows. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Removing the readings with a sample detect time of 0\n",
    "    # ids with sample detect time different than 0\n",
    "    ids = pred[pred['SampleDetectTime']!=0]['TestID'].reset_index(drop = True)\n",
    "    \n",
    "    ts = ts[ts['TestId'].isin(ids)]\n",
    "    \n",
    "    # Retrieving sample detect time for each reading that has sample detect time different than 0\n",
    "    sample_detect_time = pred[pred['SampleDetectTime'] !=0]['SampleDetectTime'].reset_index(drop = True)\n",
    "    \n",
    "    # Retrieving the index corresponding to the sample detect time.\n",
    "    # We substract terms corresponding to the number of indexes that were removed during the calculation of the moving average (i.e when the centered window is \n",
    "    # of size 31, the first 15 columns of our moving average is NA because there is not enough points to calculate the mean). These columns were removed\n",
    "    # in the function that creates the dataframe containing the moving average which is why we have to take this into consideration when finding the index.\n",
    "    \n",
    "    if center == True:\n",
    "        sample_detect_index = ((sample_detect_time/0.2) - (window - 1)/2).astype(int).reset_index(drop = True)\n",
    "       \n",
    "    else:\n",
    "        sample_detect_index = ((sample_detect_time/0.2) - (window - 1)).astype(int).reset_index(drop = True)\n",
    "        \n",
    "    # Retrieving the indices corresponding to the start and the end of the desired window\n",
    "    index = pd.concat([ids,sample_detect_time, sample_detect_index, int(start/0.2) + sample_detect_index, int(end/0.2) + sample_detect_index], axis = 1).reset_index(drop = True)\n",
    "    index.columns = [\"TestId\",\"Sample detect time\", \"Sample detect index\", \"Start\", \"End\"]\n",
    "    index['Start'] = index['Start'].astype(int)\n",
    "    index['End'] = index['End'].astype(int)\n",
    "    \n",
    "    # Merge the Start and End indices to the rolling mean dataframe\n",
    "    ts = ts.merge(index, how = 'left', on = 'TestId')\n",
    "    \n",
    "    # Select the window\n",
    "    subsets = [ts.iloc[row, ts['Start'][row]:ts['End'][row]].reset_index(drop = True) for row in range(len(ts))]\n",
    "    subsets = pd.DataFrame(subsets)\n",
    "    subsets.columns =  [str(round(m,1)) for m in np.arange(start,end, 0.2)]\n",
    "    \n",
    "    # Join the TestId to the windows \n",
    "    windowed_data = pd.concat([pd.DataFrame(ts['TestId']).reset_index(drop = True), subsets], axis = 1)\n",
    "    windowed_data = windowed_data.dropna()\n",
    "    return windowed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4b21c3-455e-4833-9ac3-a8ab5b727d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define three windows for now (use the normalized waveforms). \n",
    "# un_cal = window(start = -15, end = -3, ts = un_MA, pred = un_pred, window = 31)\n",
    "# un_post = window(start = 12, end = 16, ts = un_MA, pred = un_pred, window = 31)\n",
    "# un_sample = window(start = 32, end = 35, ts = un_MA, pred = un_pred, window = 31)\n",
    "\n",
    "# ecd_cal = window(start = -15, end =  -3, ts = ecd_MA, pred = ecd_pred_tot, window = 31)\n",
    "# ecd_post = window(start = 12, end =  16, ts = ecd_MA, pred = ecd_pred_tot, window = 31)\n",
    "# ecd_sample = window(start = 32, end = 35, ts = ecd_MA, pred = ecd_pred_tot, window = 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375f1f62-2f4d-4390-8a0f-93e3a72a91e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_smoothed(start, end, data):\n",
    "    # start and end must be strings\n",
    "    # Must include a trialing 0 for integers i.e if start = '-15', put '-15.0' instead \n",
    "    ids = data['TestId']\n",
    "    window = pd.concat([ids, data.loc[:,start:end]], axis = 1)\n",
    "    return window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a511bf0-4a00-4aaf-b365-ce64983fdf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "un_cal = window_smoothed('-15.0', '-3.0', un_MA)\n",
    "ecd_cal = window_smoothed('-15.0', '-3.0', ecd_MA)\n",
    "\n",
    "un_post = window_smoothed('12.0', '16.0', un_MA)\n",
    "ecd_post = window_smoothed('12.0', '16.0', ecd_MA)\n",
    "\n",
    "un_sample = window_smoothed('32.0', '35.0', un_MA)\n",
    "ecd_sample = window_smoothed('32.0', '35.0', ecd_MA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89894b8c-bd48-47e8-9b8c-7ca0eba31b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "un_cal = window_smoothed('-15.0', '-3.0', un_MA_w)\n",
    "ecd_cal = window_smoothed('-15.0', '-3.0', ecd_MA_w)\n",
    "\n",
    "un_post = window_smoothed('12.0', '16.0', un_MA_w)\n",
    "ecd_post = window_smoothed('12.0', '16.0', ecd_MA_w)\n",
    "\n",
    "un_sample = window_smoothed('32.0', '35.0', un_MA_w)\n",
    "ecd_sample = window_smoothed('32.0', '35.0', ecd_MA_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87931e4-9ee4-495a-9a79-ad459fa3de0a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Keeping only the TestIDs that are common in all 3 windows "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd944fb5-d2f8-4f9e-8f8b-ed42e19cccc3",
   "metadata": {},
   "source": [
    "We want to find metrics that compare the behavior in each of the windows. For example, subtracting the mean in cal to the mean in post. We can only do this for readings that are present in all of the windows (this excludes the shorter waveforms that don't make it to the post/sample window). This is why we will only consider the testids that are in the sample window (if they make it to sample, they have to also be in post and cal)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729851ea-ff63-4909-9b20-e3bdfbae7bc9",
   "metadata": {},
   "source": [
    "Lets create a dataframe containing the ECDs in the sample window to the unsuccessful readings in the sample window. We will add a label (True if ECD and False if not), to make it easier to identify which is which later once we have clustered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2394be3a-2c11-4ed0-b6c0-88dd17896596",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_un_ids = un_sample['TestId'].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b970e54-3e3e-4b75-b1fe-2da04818786e",
   "metadata": {},
   "outputs": [],
   "source": [
    "un_cal = un_cal[un_cal['TestId'].isin(common_un_ids)]\n",
    "un_post = un_post[un_post['TestId'].isin(common_un_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe9e5f1-6eb1-4565-8257-06bcfb32a2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_ecd_ids = ecd_sample['TestId'].reset_index(drop = True)\n",
    "ecd_cal = ecd_cal[ecd_cal['TestId'].isin(common_ecd_ids)]\n",
    "ecd_post = ecd_post[ecd_post['TestId'].isin(common_ecd_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24285f0-d3b2-4075-ba2b-7c184411f520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding label to differentiate ECDs from unsuccessful\n",
    "un_cal['Label'] = False\n",
    "ecd_cal['Label'] = True\n",
    "\n",
    "un_post['Label'] = False\n",
    "ecd_post['Label'] = True\n",
    "\n",
    "un_sample['Label'] = False\n",
    "ecd_sample['Label'] = True\n",
    "\n",
    "# Concatenating the ECD readings with the unsuccessful readings\n",
    "conv_cal = pd.concat([un_cal, ecd_cal], axis = 0).reset_index(drop = True)\n",
    "conv_post = pd.concat([un_post, ecd_post], axis = 0).reset_index(drop = True)\n",
    "conv_sample = pd.concat([un_sample, ecd_sample], axis = 0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a49e325-565d-41c8-85c8-6f4865f599f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_cal['mean'] = conv_cal.drop(columns = ['TestId', 'Label']).mean(axis = 1)\n",
    "conv_post['mean'] = conv_post.drop(columns = ['TestId', 'Label']).mean(axis = 1)\n",
    "conv_sample['mean'] = conv_sample.drop(columns = ['TestId', 'Label']).mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51950742-485c-480f-a53f-295ca0dce3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_feat = conv_cal[['TestId', 'Label', 'mean']]\n",
    "post_feat = conv_post[['TestId', 'Label', 'mean']]\n",
    "sample_feat = conv_sample[['TestId', 'Label', 'mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea01b52-e0c3-4bb0-a355-acf4ce94d396",
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d230fcd-2022-4870-bc2c-5d0d191737e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = cal_feat.join(post_feat[['mean', 'TestId']].set_index('TestId'), on = 'TestId', rsuffix = '_post')\n",
    "feat = feat.rename(columns = {'mean': 'mean_cal'})\n",
    "\n",
    "feat = feat.join(sample_feat[['mean', 'TestId']].set_index('TestId'), on = 'TestId', how = 'right', rsuffix = '_sample')\n",
    "feat= feat.rename(columns = {'mean': 'mean_sample'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7215f1c3-3c8e-4925-9614-3c730ff6f0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat['cal-post'] = abs(feat['mean_cal'] - feat['mean_post'])\n",
    "feat['cal-sample'] = abs(feat['mean_cal'] - feat['mean_sample'])\n",
    "feat['sample-post'] = abs(feat['mean_sample'] - feat['mean_post'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6465d1f1-f3f9-490e-9a86-42cc8d1e45c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf4adb5-6a43-4c15-9587-75c1ce7bf641",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = feat[~feat['TestId'].isin([9610647, 9610462])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebef5ec-9062-4301-a07e-7ae0c7e592ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(feat).transform_fold(\n",
    "    ['cal-post',\n",
    "     'cal-sample',\n",
    "     'sample-post'],\n",
    "    as_ = ['Measurement_type', 'value']\n",
    ").transform_density(\n",
    "    density='value',\n",
    "    bandwidth=0.3,\n",
    "    groupby=['Measurement_type'],\n",
    "    extent= [0, 1],\n",
    "    counts = True,\n",
    "    steps=200\n",
    ").mark_area().encode(\n",
    "    alt.X('value:Q'),\n",
    "    alt.Y('density:Q', stack='zero'),\n",
    "    alt.Color('Measurement_type:N')\n",
    ").properties(width=400, height=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbb6f45-5126-4ad5-8852-47d4f6745b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(feat).mark_area().transform_density(\n",
    "    'cal-post',\n",
    "    as_=['cal-post', 'density']).encode(\n",
    "    alt.X('cal-post'),\n",
    "    alt.Y('density:Q'),\n",
    "    alt.Color('Label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1aa095-2ea2-4c41-8e91-6550fc0d85b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "alt.data_transformers.enable('default', max_rows=None)\n",
    "alt.Chart(feat).mark_boxplot(size=50).encode(\n",
    "    x='Label',\n",
    "    y=alt.Y('cal-post'),\n",
    "    color=alt.Color('Label')\n",
    ").properties(width=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c13c20e-8ace-4f40-a291-e97e21d323e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "alt.data_transformers.enable('default', max_rows=None)\n",
    "alt.Chart(feat).mark_boxplot(size=50).encode(\n",
    "    x='Label',\n",
    "    y=alt.Y('cal-sample'),\n",
    "    color=alt.Color('Label')\n",
    ").properties(width=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdaa89c-81a3-407c-910d-20ca0362e4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "alt.data_transformers.enable('default', max_rows=None)\n",
    "alt.Chart(feat).mark_boxplot(size=50).encode(\n",
    "    x='Label',\n",
    "    y=alt.Y('sample-post'),\n",
    "    color=alt.Color('Label')\n",
    ").properties(width=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9326707b-db6e-4f1d-ad42-d32de219ea5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
