{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b96a5eef-4b7b-4b28-8a4e-99e664efa251",
   "metadata": {},
   "source": [
    "# **Description**\n",
    "This notebook was used in the first iteration to separate the files into widows relative to sample detect time. It wasn't great though because the indexing was highly dependent on the amount of wet-up removed. A much better function for this (window_after_zeroed()) is included in the final preprocessing notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221bbada-cc4e-4ce1-bdac-30a9992c4c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the time series into segments based on sample detect time. \n",
    "# Will turn into a script later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9eff0fb-ad18-481e-97f1-249428ac9c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "ecd_ts = pd.read_csv('/Users/saral/OneDrive - UBC/MDS/Capstone/Code + Data/Data/Time Series/ECDTS/ECD_TS_STAND.csv')\n",
    "un_ts = pd.read_csv('/Users/saral/OneDrive - UBC/MDS/Capstone/Code + Data/Data/Time Series/unsuccesful time series/US_TS_STAND.csv')\n",
    "sy_ts = pd.read_csv('/Users/saral/OneDrive - UBC/MDS/Capstone/Code + Data/Data/Time Series/ECDTS/ECD_TS_SYNTH_STAND.csv')\n",
    "con_ts =  pd.read_csv('/Users/saral/OneDrive - UBC/MDS/Capstone/Code + Data/Data/Time Series/ECDTS/ECD_TS_Contaminated.csv')\n",
    "\n",
    "un_pred = pd.read_csv('/Users/saral/OneDrive - UBC/MDS/Capstone/Code + Data/Data/Raw Data Predictors/Unsuccessful.csv')\n",
    "ecd_pred = pd.read_csv('/Users/saral/OneDrive - UBC/MDS/Capstone/Code + Data/Data/Raw Data Predictors/ECD.csv')\n",
    "sy_pred = pd.read_csv('/Users/saral/OneDrive - UBC/MDS/Capstone/Code + Data/Data/Raw Data Predictors/SyntheticPC.csv')\n",
    "con_pred =  pd.read_csv('/Users/saral/OneDrive - UBC/MDS/Capstone/Code + Data/Data/Raw Data Predictors/PCAggContaminated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5b9d13-33b9-4aec-9473-24c53d18ded4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove readings with Sample Detect Time of 0. \n",
    "un_ts = un_ts[un_ts['TestId'].isin(un_pred['TestID'][un_pred['SampleDetectTime']!=0])]\n",
    "sy_ts = sy_ts[sy_ts['TestId'].isin(sy_pred['TestID'][sy_pred['SampleDetectTime']!=0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d35a3a-eb49-438f-82f2-bee8c3e75817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram with the lengths of the unsuccessful readings\n",
    "junk = plt.hist(len(un_ts.columns) - un_ts.isnull().sum(axis=1), bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3936f2a-5b54-4a49-b632-32cdd4baa6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram with the lengths of the ECD readings\n",
    "junk = plt.hist(len(ecd_ts.columns) - ecd_ts.isnull().sum(axis=1), bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1ba384-c222-42e1-924c-b1215b19e9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram with the lengths of the synthetic ECD readings\n",
    "junk = plt.hist(len(sy_ts.columns) - sy_ts.isnull().sum(axis=1), bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594f4e37-07b5-4de3-a089-268125043816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median unsuccessful reading. \n",
    "t = np.arange(150, 300.2, 0.2)\n",
    "plt.plot(t, un_ts.median()[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12ba94f-d8f9-4853-96f5-cd4000dc914b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median 'wild' ECD reading. \n",
    "plt.plot(t, ecd_ts.median()[1:])\n",
    "np.mean(ecd_pred['SampleDetectTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc00123-db6d-48ca-bc8e-f95c19ddb40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median synthetic ECD reading. \n",
    "plt.plot(t, sy_ts.median()[1:])\n",
    "np.mean(sy_pred['SampleDetectTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea935e0f-57f9-4e4b-be41-418198f9e4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the times series based on start and end times relative to sample detect time. \n",
    "# start - seconds to start from relative to sample detect (eg. -5 would start 5 seconds before, 5 would start 5 seconds after)\n",
    "# end - seconds to end from relative to sample detect. \n",
    "# ts - data frame where each row is a time series\n",
    "# pred - data frame where each row is a reading, has the sample detect time column. \n",
    "def window(start, end, ts, pred):\n",
    "    # Get the list of IDs for both data sources. \n",
    "    ts_ids = ts['TestId']\n",
    "    pred_ids = pred['TestID']\n",
    "    \n",
    "    # Convert sample detect time to samples from second; subtract 750 as that's the number of samples removed for wet-up. \n",
    "    sample_detect = (pred['SampleDetectTime']/0.2).astype(int) - 750\n",
    "    \n",
    "    # Make a data frame with test ids, and start and end indices to window based on. \n",
    "    # Add 1s to indices to ignore the first column (which has test ids). \n",
    "    index = pd.concat([pred_ids, int(start/0.2)+sample_detect+1, int(end/0.2) +sample_detect+1], axis = 1)\n",
    "    index.columns = [\"TestId\", \"Start\", \"End\"]\n",
    "    # Merge start and end indices into time series data frame based on ids. \n",
    "    ts = ts.merge(index, how = 'left', on = 'TestId')\n",
    "    # Save the order of ids for later use. \n",
    "    ids = ts['TestId']\n",
    "    \n",
    "    #Subset each time series based on it's start and end indices. \n",
    "    subsets = [ts.iloc[row, ts['Start'][row]:ts['End'][row]].reset_index(drop = True) for row in range(len(ts))]\n",
    "    \n",
    "    #Return a dataframe with test ids reatttached. \n",
    "    return pd.concat([pd.DataFrame(ids), pd.DataFrame(subsets)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5176055-931a-4d8c-96f1-129ffc817185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define three windows for now. \n",
    "un_cal = window(-15, -3, un_ts, un_pred)\n",
    "ecd_cal = window(-15, -3, ecd_ts, ecd_pred)\n",
    "syn_cal = window(-15, -3, sy_ts, sy_pred)\n",
    "\n",
    "un_post = window(12, 16, un_ts, un_pred)\n",
    "ecd_post = window(12, 16, ecd_ts, ecd_pred)\n",
    "syn_post = window(12, 16, sy_ts, sy_pred)\n",
    "\n",
    "un_sample = window(32, 35, un_ts, un_pred)\n",
    "ecd_sample = window(32, 35, ecd_ts, ecd_pred)\n",
    "syn_sample = window(32, 35, sy_ts, sy_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf76b062-f649-4f38-ba8a-656b9b9a14b4",
   "metadata": {},
   "source": [
    "# Drop rows with NAs. Might want to come back later and play with adjusting the wet-up period to be variable depending on sample detect time, but for now just leave it. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b15128-f884-4c7e-8beb-c6cecefa553e",
   "metadata": {},
   "outputs": [],
   "source": [
    "un_cal.dropna().to_csv('/Users/saral/OneDrive - UBC/MDS/Capstone/Code + Data/Data/Windowed Time Series/un_cal.csv', index = False)\n",
    "un_post.dropna().to_csv('/Users/saral/OneDrive - UBC/MDS/Capstone/Code + Data/Data/Windowed Time Series/un_post.csv', index = False)\n",
    "un_sample.dropna().to_csv('/Users/saral/OneDrive - UBC/MDS/Capstone/Code + Data/Data/Windowed Time Series/un_sample.csv',  index = False)\n",
    "\n",
    "ecd_cal.dropna().to_csv('/Users/saral/OneDrive - UBC/MDS/Capstone/Code + Data/Data/Windowed Time Series/ecd_cal.csv', index = False)\n",
    "ecd_post.dropna().to_csv('/Users/saral/OneDrive - UBC/MDS/Capstone/Code + Data/Data/Windowed Time Series/ecd_post.csv', index = False)\n",
    "ecd_sample.dropna().to_csv('/Users/saral/OneDrive - UBC/MDS/Capstone/Code + Data/Data/Windowed Time Series/ecd_sample.csv',  index = False)\n",
    "\n",
    "syn_cal.dropna().to_csv('/Users/saral/OneDrive - UBC/MDS/Capstone/Code + Data/Data/Windowed Time Series/syn_cal.csv', index = False)\n",
    "syn_post.dropna().to_csv('/Users/saral/OneDrive - UBC/MDS/Capstone/Code + Data/Data/Windowed Time Series/syn_post.csv', index = False)\n",
    "syn_sample.dropna().to_csv('/Users/saral/OneDrive - UBC/MDS/Capstone/Code + Data/Data/Windowed Time Series/syn_sample.csv',  index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b72fda-6a80-40fd-8334-f51ddc11bfaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03f9b76-c137-4b38-8ee9-7042dc4f2fa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
