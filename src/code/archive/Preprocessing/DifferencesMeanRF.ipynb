{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f8003d-63f8-466b-a6d9-c14e1a798a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6365e0-e7da-45f6-9c61-0c211d04bd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timeseries\n",
    "analyte_b = pd.read_csv(\"../../../data/TimeSeriesData/ecdContactTS/ECD_A2_all.csv\")\n",
    "ecd = pd.read_csv(\"../../../data/TimeSeriesData/ecdContactTS/ECD_TS.csv\")\n",
    "ecd_syn = pd.read_csv(\"../../../data/TimeSeriesData/ecdContactTS/ECD_TS_Synthetic.csv\")\n",
    "ecd_con = pd.read_csv(\"../../../data/TimeSeriesData/ecdContactTS/ECD_TS_Contaminated.csv\")\n",
    "un = pd.read_csv(\"../../../data/TimeSeriesData/UnsuccessfulReadingsTS/US_TS.csv\")\n",
    "\n",
    "ecd_tot = pd.concat([ecd, ecd_syn, ecd_con])\n",
    "\n",
    "# Predictors\n",
    "un_pred = pd.read_csv('../../../data/RawDataPredictors/New/Unsuccessful.csv')\n",
    "ecd_pred = pd.read_csv('../../../data/RawDataPredictors/New/ecdContact.csv')\n",
    "syn_pred = pd.read_csv('../../../data/RawDataPredictors/New/SyntheticECD.csv')\n",
    "con_pred = pd.read_csv('../../../data/RawDataPredictors/New/ECDAggContaminated.csv')\n",
    "\n",
    "ecd_pred_tot = pd.concat([ecd_pred, syn_pred, con_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa47950e-c94a-4422-a090-1e92ef637da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyte_b_1 = analyte_b[analyte_b['TestId'] == 8105859].drop(columns = ['TestId', ' Channel'], axis = 1).iloc[0].dropna()\n",
    "analyte_a_1 = ecd[ecd['TestId'] == 8105859].drop(columns = ['TestId'], axis = 1).iloc[0].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836ed88d-ee2f-4371-90cd-1ccffe60a4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_un = np.arange(0, len(un), 1)  \n",
    "x_b = np.arange(0, len(analyte_b_1), 1)\n",
    "x_a = np.arange(0, len(analyte_a_1), 1)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "axes[0].plot(x_b[1200:1400], analyte_b_1[1200:1400])\n",
    "axes[1].plot(x_a[1200:1400], analyte_a_1[1200:1400])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3d4aa7-2c7e-462e-a413-a20cf03c2105",
   "metadata": {},
   "source": [
    "## Creating Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78074ea9-05c1-4254-837c-4d56bddef2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the normalized data, and then apply the moving average\n",
    "ecd_norm = pd.read_csv(\"../../../data/TimeSeriesData/Normalized/ecd_norm_window.csv\")\n",
    "ecd_syn_norm = pd.read_csv(\"../../../data/TimeSeriesData/Normalized/syn_norm_window.csv\")\n",
    "ecd_con_norm = pd.read_csv(\"../../../data/TimeSeriesData/Normalized/cont_norm_window.csv\")\n",
    "un_norm = pd.read_csv(\"../../../data/TimeSeriesData/Normalized/un_norm_window.csv\")\n",
    "\n",
    "ecd_tot_norm = pd.concat([ecd_norm, ecd_syn_norm, ecd_con_norm], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fc4c29-72c5-447e-818d-dfb46d8a4ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_moving_average_data(data, window, center = True):\n",
    "    rolling_data = data.drop(columns = 'TestId').rolling(window, axis = 1, center = center).mean().dropna(axis = 1, how = 'all').reset_index(drop = True)\n",
    "    rolling_data['TestId'] = data['TestId'].reset_index(drop = True)\n",
    "    rolling_data = rolling_data.dropna(axis = 0, thresh = 2).reset_index(drop = True) # For series that are smaller than window\n",
    "    return rolling_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c36748-9bfa-49cd-ac2b-fc73fddb1e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecd_rolling_norm = creating_moving_average_data(ecd_tot_norm, 31)\n",
    "un_rolling_norm = creating_moving_average_data(un_norm, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711843bf-3071-47a2-b812-539b4d8c2241",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d82a30-0827-4b62-b85c-db81beee47e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average_plot(rolling_data, raw_data, num_plots):\n",
    "    for i in range(num_plots):\n",
    "        testid = 8883093\n",
    "        #int(rolling_data.iloc[i,:]['TestId'])\n",
    "\n",
    "\n",
    "        MA = rolling_data[rolling_data['TestId'] == testid].drop(columns = 'TestId').iloc[0].dropna()\n",
    "        raw = raw_data[raw_data['TestId'] == testid].drop(columns = 'TestId').iloc[0].dropna()\n",
    "\n",
    "        raw = pd.DataFrame(raw)\n",
    "        raw = raw.rename(columns = {raw.columns[0]: 'raw'})\n",
    "\n",
    "        MA = pd.DataFrame(MA)\n",
    "        MA = MA.rename(columns = {MA.columns[0]: 'MA'})\n",
    "\n",
    "        raw_MA_combined = raw.join(MA).dropna(axis = 0)\n",
    "        \n",
    "        plot1 = raw_MA_combined[['raw', 'MA']].plot(figsize=(10, 5), title = f'Trace for TestId : {testid}')\n",
    "        plot1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f22ea14-40bc-4b6d-9065-e68cd0e96678",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ecd_sara = window(start = -30, end =  40, ts = ecd_rolling_norm, pred = ecd_pred_tot, window = 31)\n",
    "moving_average_plot(ecd_rolling_norm, ecd_tot_norm, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9e0e5d-54d6-4df2-846e-6d9eb0e55908",
   "metadata": {},
   "outputs": [],
   "source": [
    "sara = ecd_rolling_norm[ecd_rolling_norm['TestId'] == 8883093]\n",
    "sara.to_csv('MA_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd48aaf-6f1b-4df8-9382-bae944c1954b",
   "metadata": {},
   "source": [
    "## Visualizations of Moving Average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6f4569-21b0-4172-b00f-ab573f181e4f",
   "metadata": {},
   "source": [
    "#### Remove Wet-up --> Normalized --> Applied moving average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b658891-2cfd-4004-adf6-b3e9d4527ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = 83\n",
    "ide = ecd['TestId'][loc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d523275-4c5f-4da5-bb59-10bc283b5a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_start = int(ecd_pred[ecd_pred['TestID'] == ide]['SampleDetectTime'].item()/0.2)\n",
    "window_start = int(-30/0.2)\n",
    "window_end = int(40/0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746104f0-0964-47e4-af82-af6a61983843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the wetup periods\n",
    "analyte_b_window = analyte_b[analyte_b['TestId'] == ide].iloc[:, sample_start + window_start + 2:sample_start+window_end+2]\n",
    "analyte_a_window = ecd[ecd['TestId'] == ide].iloc[:, sample_start + window_start + 1 :sample_start + window_end + 1]\n",
    "\n",
    "# We add 15 because we are doing a centered rolling mean with a window of 31 (15 on each side)\n",
    "moving_window = ecd[ecd['TestId'] == ide].iloc[:, sample_start + window_start -15 + 1  :sample_start + window_end + 15 + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84894760-a145-4909-b43a-fa93d068eb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyte_a_norm = (analyte_a_window - analyte_a_window.min(axis = 1).item() )/ (analyte_a_window.max(axis = 1).item() - analyte_a_window.min(axis = 1).item())\n",
    "analyte_b_norm = (analyte_b_window - analyte_b_window.min(axis = 1).item() )/ (analyte_b_window.max(axis = 1).item() - analyte_b_window.min(axis = 1).item())\n",
    "moving_norm = (moving_window - moving_window.min(axis = 1).item() )/ (moving_window.max(axis = 1).item() - moving_window.min(axis = 1).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f633189-beeb-4a88-a2fd-40ce92cd8567",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_norm = moving_norm.rolling(window = 31, axis = 1, center = True).mean().dropna(axis = 1, how = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0a6661-9ecf-4ae8-b03c-ed0a3a1c02d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(window_start, window_end)\n",
    "plt.plot(x, analyte_b_norm.transpose(), c = 'b', label = 'analyte_b', alpha = 0.3)\n",
    "plt.plot(x, analyte_a_norm.transpose(), c = 'r', label = 'analyte_a', alpha = 0.3)\n",
    "plt.plot(x, rolling_norm.transpose(), c = 'r', label = 'Rolling average for analyte_a')\n",
    "plt.xlabel(\"Index w.r.t sample detection\")\n",
    "plt.ylabel(\"Normalized Signal\")\n",
    "plt.title(\"Comparision of normalized signals\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8379bcd9-3506-4f9b-8e33-196c046a13ca",
   "metadata": {},
   "source": [
    "#### Pulling out smaller window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7035ea-157c-4f45-b080-5c5d0bf4ac20",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_win_start = int(-15/0.2)\n",
    "small_win_end = int(-3/0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a75eec-3d0b-4b14-aac7-4fd60935a2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyte_b_cal = analyte_b_norm.iloc[:, small_win_start:small_win_end]\n",
    "analyte_a_cal = analyte_a_norm.iloc[:, small_win_start:small_win_end]\n",
    "ma_cal = rolling_norm.iloc[:, small_win_start:small_win_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2a1d8c-ea65-4824-9518-7431f891ef07",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(small_win_start,small_win_end)\n",
    "plt.plot(x, analyte_b_cal.transpose(), c = 'b', label = 'analyte_b', alpha = 0.3)\n",
    "plt.plot(x, analyte_a_cal.transpose(), c = 'r', label = 'analyte_a', alpha = 0.3)\n",
    "plt.plot(x, ma_cal.transpose(), c = 'r', label = 'Rolling average for analyte_a')\n",
    "plt.xlabel(\"Index w.r.t sample detection\")\n",
    "plt.ylabel(\"Normalized Signal\")\n",
    "plt.title(\"Comparision of normalized signals for calibration window\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f11202-3cd5-4345-b695-bad7b5b1b4a3",
   "metadata": {},
   "source": [
    "#### Look at the power spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b625a653-98ee-48ac-9768-75a09d406630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the power spectra in a featureless region\n",
    "f, ps = signal.periodogram(analyte_a_cal, fs = 5)\n",
    "f1, ps_1 = signal.periodogram(ma_cal, fs = 5)\n",
    "f2, ps_2 = signal.periodogram(analyte_b_cal, fs = 5)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "with plt.style.context(('ggplot')):\n",
    "    plt.plot(f, ps[0], 'r', label = 'analyte_a, no smoothing', alpha = 0.3)\n",
    "    plt.plot(f1, ps_1[0], 'r', label = 'Moving average')\n",
    "    plt.plot(f2, ps_2[0], 'b', label = 'analyte_b', alpha = 0.3)\n",
    "    plt.legend()\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Power')\n",
    "    plt.title('Overlayed power spectral density estimations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2915f452-d68e-4812-b88f-3ef6f8719662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the power spectra in a featureless region\n",
    "f, ps = signal.periodogram(analyte_a_cal, fs = 5)\n",
    "f1, ps_1 = signal.periodogram(ma_cal, fs = 5)\n",
    "f2, ps_2 = signal.periodogram(analyte_b_cal, fs = 5)\n",
    "\n",
    " \n",
    " \n",
    "plt.figure(figsize=(10,8))\n",
    "with plt.style.context(('ggplot')):\n",
    "    plt.plot(f1, ps_1[0], 'r', label = 'Moving average')\n",
    "    plt.plot(f2, ps_2[0], 'b', label = 'analyte_b', alpha = 0.3)\n",
    "    plt.legend()\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Power')\n",
    "    plt.title('Overlayed power spectral density estimations')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc926b7-4bd9-4b5b-9243-74210b502706",
   "metadata": {},
   "source": [
    "## Windowing Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c4a5fd-6cdc-4473-8415-366eec462870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timeseries\n",
    "# We use the normalized data, and then apply the moving average\n",
    "ecd_norm = pd.read_csv(\"../../../data/TimeSeriesData/Normalized/ecd_norm.csv\")\n",
    "ecd_syn_norm = pd.read_csv(\"../../../data/TimeSeriesData/Normalized/syn_norm.csv\")\n",
    "ecd_con_norm = pd.read_csv(\"../../../data/TimeSeriesData/Normalized/cont_norm.csv\")\n",
    "un_norm = pd.read_csv(\"../../../data/TimeSeriesData/Normalized/un_norm.csv\")\n",
    "\n",
    "ecd_tot_norm = pd.concat([ecd_norm, ecd_syn_norm, ecd_con_norm], axis = 0)\n",
    "\n",
    "# Predictors\n",
    "un_pred = pd.read_csv('../../../data/RawDataPredictors/New/Unsuccessful.csv')\n",
    "ecd_pred = pd.read_csv('../../../data/RawDataPredictors/New/ecdContact.csv')\n",
    "syn_pred = pd.read_csv('../../../data/RawDataPredictors/New/SyntheticECD.csv')\n",
    "con_pred = pd.read_csv('../../../data/RawDataPredictors/New/ECDAggContaminated.csv')\n",
    "\n",
    "ecd_pred_tot = pd.concat([ecd_pred, syn_pred, con_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9c7c0d-bcc1-4160-91d3-20dfa8e33a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecd_rolling_norm = creating_moving_average_data(ecd_tot_norm, 31)\n",
    "un_rolling_norm = creating_moving_average_data(un_norm, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970478cb-eb91-4883-8722-155a0de5b3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window(start, end, ts, pred, window, center = True):\n",
    "    \"\"\"Windows the data output by the `creating_moving_average_data` function. \n",
    "\n",
    "    Args:\n",
    "        start (int): Start of window with respect to sample detect time (i.e -15 represents 15 seconds before sample detect)\n",
    "        end (int): End of window with respect to sample detect time (i.e 30 represents 30 seconds after sample detect)\n",
    "        ts (pandas data frame): Output from the `creating_moving_average` function (a dataframe containing the moving averages). \n",
    "        pred (pandas data frame): Dataframe containg the predictor file containing a column with the SampleDetectTime (i.e when windowing the unsuccessful readings, use the predictor file for the unsuccessul readings).\n",
    "        window (int): The window that was used when calculating the moving average for the ts dataframe (needs to be an odd number if centered).\n",
    "        center (bool, default = True): Whether or not the moving average that was calculated for the ts dataframe was centered (True) or not(False).\n",
    "\n",
    "    Returns:\n",
    "        A new pandas data frame with z-normalized time series stored in the rows. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Removing the readings with a sample detect time of 0\n",
    "    # ids with sample detect time different than 0\n",
    "    ids = pred[pred['SampleDetectTime']!=0]['TestID'].reset_index(drop = True)\n",
    "    \n",
    "    ts = ts[ts['TestId'].isin(ids)]\n",
    "    \n",
    "    # Retrieving sample detect time for each reading that has sample detect time different than 0\n",
    "    sample_detect_time = pred[pred['SampleDetectTime'] !=0]['SampleDetectTime'].reset_index(drop = True)\n",
    "    \n",
    "    # Retrieving the index corresponding to the sample detect time.\n",
    "    # We substract terms corresponding to the number of indexes that were removed during the calculation of the moving average (i.e when the centered window is \n",
    "    # of size 31, the first 15 columns of our moving average is NA because there is not enough points to calculate the mean). These columns were removed\n",
    "    # in the function that creates the dataframe containing the moving average which is why we have to take this into consideration when finding the index.\n",
    "    \n",
    "    if center == True:\n",
    "        sample_detect_index = ((sample_detect_time/0.2) - (window - 1)/2).astype(int).reset_index(drop = True)\n",
    "       \n",
    "    else:\n",
    "        sample_detect_index = ((sample_detect_time/0.2) - (window - 1)).astype(int).reset_index(drop = True)\n",
    "        \n",
    "    # Retrieving the indices corresponding to the start and the end of the desired window\n",
    "    index = pd.concat([ids,sample_detect_time, sample_detect_index, int(start/0.2) + sample_detect_index, int(end/0.2) + sample_detect_index], axis = 1).reset_index(drop = True)\n",
    "    index.columns = [\"TestId\",\"Sample detect time\", \"Sample detect index\", \"Start\", \"End\"]\n",
    "    index['Start'] = index['Start'].astype(int)\n",
    "    index['End'] = index['End'].astype(int)\n",
    "    \n",
    "    # Merge the Start and End indices to the rolling mean dataframe\n",
    "    ts = ts.merge(index, how = 'left', on = 'TestId')\n",
    "    \n",
    "    # Select the window\n",
    "    subsets = [ts.iloc[row, ts['Start'][row]:ts['End'][row]].reset_index(drop = True) for row in range(len(ts))]\n",
    "    subsets = pd.DataFrame(subsets)\n",
    "    subsets.columns =  [str(round(m,1)) for m in np.arange(start,end, 0.2)]\n",
    "    \n",
    "    # Join the TestId to the windows \n",
    "    windowed_data = pd.concat([pd.DataFrame(ts['TestId']).reset_index(drop = True), subsets], axis = 1)\n",
    "    windowed_data = windowed_data.dropna()\n",
    "    return windowed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5117d2b-220e-4577-8614-6be2c2087ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define three windows for now (use the normalized waveforms). \n",
    "un_cal = window(start = -15, end = -3, ts = un_rolling_norm, pred = un_pred, window = 31)\n",
    "un_post = window(start = 12, end = 16, ts = un_rolling_norm, pred = un_pred, window = 31)\n",
    "un_sample = window(start = 32, end = 35, ts = un_rolling_norm, pred = un_pred, window = 31)\n",
    "\n",
    "ecd_cal = window(start = -15, end =  -3, ts = ecd_rolling_norm, pred = ecd_pred_tot, window = 31)\n",
    "ecd_post = window(start = 12, end =  16, ts = ecd_rolling_norm, pred = ecd_pred_tot, window = 31)\n",
    "ecd_sample = window(start = 32, end = 35, ts = ecd_rolling_norm, pred = ecd_pred_tot, window = 31)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66003d00-9419-4b64-8e6a-6d068442a3a0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "We want to find metrics that compare the behavior in each of the windows. For example, subtracting the mean in cal to the mean in post. We can only do this for readings that are present in all of the windows (this excludes the shorter waveforms that don't make it to the post/sample window). This is why we will only consider the testids that are in the sample window (if they make it to sample, they have to also be in post and cal)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780b5644-3012-435c-bcbc-2060fa254a31",
   "metadata": {},
   "source": [
    "Lets create a dataframe containing the ecd contacts in the sample window to the unsuccessful readings in the sample window. We will add a label (True if ecd and False if not), to make it easier to identify which is which later once we have clustered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8f9353-ae7c-484d-8964-95bf78ccff3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeecdg only the TestId that are in all 3 windows (meaning only the ids that remain in the sample window)\n",
    "common_ids = un_sample['TestId'].reset_index(drop = True)\n",
    "un_cal = un_cal[un_cal['TestId'].isin(common_ids)]\n",
    "un_post = un_post[un_post['TestId'].isin(common_ids)]\n",
    "\n",
    "common_ecd_ids = ecd_sample['TestId'].reset_index(drop = True)\n",
    "ecd_cal = ecd_cal[ecd_cal['TestId'].isin(common_ecd_ids)]\n",
    "ecd_post = ecd_post[ecd_post['TestId'].isin(common_ecd_ids)]\n",
    "\n",
    "# Adding label to differentiate ecds from unsuccessful\n",
    "un_cal['Label'] = False\n",
    "ecd_cal['Label'] = True\n",
    "\n",
    "un_post['Label'] = False\n",
    "ecd_post['Label'] = True\n",
    "\n",
    "un_sample['Label'] = False\n",
    "ecd_sample['Label'] = True\n",
    "\n",
    "# Concatenating the ecd contact readings with the unsuccessful readings\n",
    "MA_cal = pd.concat([un_cal, ecd_cal], axis = 0).reset_index(drop = True)\n",
    "MA_post = pd.concat([un_post, ecd_post], axis = 0).reset_index(drop = True)\n",
    "MA_sample = pd.concat([un_sample, ecd_sample], axis = 0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9ebafc-bf5f-40ba-9b03-a7723456c3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MA_cal['mean'] = MA_cal.drop(columns = ['TestId', 'Label']).mean(axis = 1)\n",
    "MA_post['mean'] = MA_post.drop(columns = ['TestId', 'Label']).mean(axis = 1)\n",
    "MA_sample['mean'] = MA_sample.drop(columns = ['TestId', 'Label']).mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0950b894-f960-486d-875d-3e5ad292cfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Calibration period for unsuccessful\n",
    "x = [float(x) for x in MA_cal.drop(columns = ['mean', 'Label', 'TestId']).columns]\n",
    "number_of_lines = 250\n",
    "for row in range(number_of_lines):\n",
    "    y = MA_cal[MA_cal['Label'] == False].drop(columns = ['mean', 'Label', 'TestId']).iloc[row,:]\n",
    "    plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78280911-33bb-47d1-8476-3d3980e3bef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration period for ecd\n",
    "x = [float(x) for x in MA_cal.drop(columns = ['mean', 'Label', 'TestId']).columns]\n",
    "number_of_lines = 250\n",
    "for row in range(number_of_lines):\n",
    "    y = MA_cal[MA_cal['Label'] == True].drop(columns = ['mean', 'Label', 'TestId']).iloc[row,:]\n",
    "    plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f074968-e24d-4d07-a4eb-15d61a45451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post period for unsuccessful\n",
    "x = [float(x) for x in MA_post.drop(columns = ['mean', 'Label', 'TestId']).columns]\n",
    "number_of_lines = 250\n",
    "for row in range(number_of_lines):\n",
    "    y = MA_post[MA_post['Label'] == False].drop(columns = ['mean', 'Label', 'TestId']).iloc[row,:]\n",
    "    plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a07a1a6-28d0-4caf-9560-dac1bd4cd35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post period for ecds\n",
    "x = [float(x) for x in MA_post.drop(columns = ['mean', 'Label', 'TestId']).columns]\n",
    "number_of_lines = 250\n",
    "for row in range(number_of_lines):\n",
    "    y = MA_post[MA_post['Label'] == True].drop(columns = ['mean', 'Label', 'TestId']).iloc[row,:]\n",
    "    plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b3931c-7c1b-4d24-9d69-865cb3d24679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample period for unsuccessful\n",
    "x = [float(x) for x in MA_sample.drop(columns = ['mean', 'Label', 'TestId']).columns]\n",
    "number_of_lines = 250\n",
    "for row in range(number_of_lines):\n",
    "    y = MA_sample[MA_sample['Label'] == False].drop(columns = ['mean', 'Label', 'TestId']).iloc[row,:]\n",
    "    plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2cd2fb-0a3a-487e-a144-f2210789d1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample period for ecds\n",
    "x = [float(x) for x in MA_sample.drop(columns = ['mean', 'Label', 'TestId']).columns]\n",
    "number_of_lines = 250\n",
    "for row in range(number_of_lines):\n",
    "    y = MA_sample[MA_sample['Label'] == True].drop(columns = ['mean', 'Label', 'TestId']).iloc[row,:]\n",
    "    plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4733e6eb-b2c7-4c9e-b9d5-ce76f637b425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete waveform for unsuccessful\n",
    "number_of_lines = 250\n",
    "for row in range(number_of_lines):\n",
    "    x = [float(x) for x in un_rolling.drop(columns = ['TestId']).iloc[row,:].dropna().index]\n",
    "    y = un_rolling.drop(columns = ['TestId']).iloc[row,:].dropna()\n",
    "    plt.plot(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c68d3f7-1567-4e07-82c2-95c758f1a27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete waveform for ecds\n",
    "number_of_lines = 250\n",
    "for row in range(number_of_lines):\n",
    "    x = [float(x) for x in ecd_rolling.drop(columns = ['TestId']).iloc[row,:].dropna().index]\n",
    "    y = ecd_rolling.drop(columns = ['TestId']).iloc[row,:].dropna()\n",
    "    plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c4eb7f-6a56-44ca-9ef5-6bf8807fc9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_feat = MA_cal[['TestId', 'Label', 'mean']]\n",
    "post_feat = MA_post[['TestId', 'Label', 'mean']]\n",
    "sample_feat = MA_sample[['TestId', 'Label', 'mean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4210a1b-3f71-459b-af28-540086691ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = cal_feat.join(post_feat[['mean', 'TestId']].set_index('TestId'), on = 'TestId', rsuffix = '_post')\n",
    "feat = feat.rename(columns = {'mean': 'mean_cal'})\n",
    "\n",
    "feat = feat.join(sample_feat[['mean', 'TestId']].set_index('TestId'), on = 'TestId', how = 'right', rsuffix = '_sample')\n",
    "feat= feat.rename(columns = {'mean': 'mean_sample'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc66bbc0-30a8-4ffd-ba0e-be7f34f6e86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat['cal-post'] = abs(feat['mean_cal'] - feat['mean_post'])\n",
    "feat['cal-sample'] = abs(feat['mean_cal'] - feat['mean_sample'])\n",
    "feat['sample-post'] = abs(feat['mean_sample'] - feat['mean_post'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26aca4e-4650-4707-a6af-14f0238f7426",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e1acda-54f1-4ff3-ad70-856262d13565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb4011e-4189-4297-83e2-1468a9ea66e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.data_transformers.enable('default', max_rows=None)\n",
    "alt.Chart(feat).mark_boxplot(size=50).encode(\n",
    "    x='Label',\n",
    "    y=alt.Y('cal-post'),\n",
    "    color=alt.Color('Label')\n",
    ").properties(width=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f6a9cc-85d8-4c63-8116-42c53eea51b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.data_transformers.enable('default', max_rows=None)\n",
    "alt.Chart(feat).mark_boxplot(size=50).encode(\n",
    "    x='Label',\n",
    "    y=alt.Y('cal-sample'),\n",
    "    color=alt.Color('Label')\n",
    ").properties(width=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440100db-a4d1-44ee-91cf-4db2a10c1727",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.data_transformers.enable('default', max_rows=None)\n",
    "alt.Chart(feat).mark_boxplot(size=50).encode(\n",
    "    x='Label',\n",
    "    y=alt.Y('sample-post'),\n",
    "    color=alt.Color('Label')\n",
    ").properties(width=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfe3297-93a9-43f0-8756-245dc08936b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c8c280-7fcb-473b-b620-0b8c0d22994a",
   "metadata": {},
   "source": [
    "## RANDOM FOREST (FOR CURIOSITY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034af232-d311-425c-9372-c60a54e43838",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929862dc-f5f9-42b9-a19d-0ce4da272ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = feat[['mean_cal', 'mean_post', 'mean_sample', 'cal-post', 'cal-sample', 'sample-post']]\n",
    "y = feat[['Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb28568-d0e7-40b4-823c-876a1198a545",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, stratify = y, random_state = 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707ef74f-18fd-4a57-8243-ec75324c94d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {'balanced_accuracy': metrics.make_scorer(metrics.balanced_accuracy_score), \n",
    "           'precision': metrics.make_scorer(metrics.precision_score),\n",
    "          'recall' : metrics.make_scorer(metrics.recall_score),\n",
    "          'f1' : metrics.make_scorer(metrics.f1_score),\n",
    "          'log-loss' : metrics.make_scorer(metrics.log_loss)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59527027-e05f-41b5-a3ff-ce5871b84a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"% of ecds in training set: {np.round(np.mean(y_train['Label'])*100,3)}\")\n",
    "print(f\"% of ecds in testing set: {np.round(np.mean(y_test['Label'])*100,3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b65c0f-2e51-4f47-9299-53913156bdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets fit a rf with default parameters\n",
    "rf_default = RandomForestClassifier(random_state = 2022)\n",
    "\n",
    "# Define evaluation procedure\n",
    "cv_rf_default = cross_validate(rf_default, X = X_train, y = y_train,scoring = metrics, n_jobs = -1, cv = 5, verbose = 1)\n",
    "\n",
    "pd.DataFrame.from_dict(cv_rf_default).set_axis(['Fold_1', 'Fold_2', 'Fold_3', 'Fold_4', 'Fold_5'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c751e9d4-31c3-4f4a-83b9-bcfbe858a8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average of all folds\n",
    "metrics_rf_default = pd.DataFrame.from_dict(cv_rf_default).set_axis(['Fold_1', 'Fold_2', 'Fold_3', 'Fold_4', 'Fold_5'], axis=0).mean(axis = 0)\n",
    "metrics_rf_default = pd.DataFrame(metrics_rf_default).set_axis(['Avg Fit Time', 'Avg Score Time', '5-Fold Balanced Accuracy', '5-Fold Precision', '5-Fold Recall', '5-Fold F1', '5-Fold Log Loss'], axis = 0).T.set_axis(['Random Forest'])\n",
    "metrics_rf_default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2abfac4-314d-4e0f-b577-ee81a139597e",
   "metadata": {},
   "source": [
    "## With the returncode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0289305-fa2a-4cf5-9823-b799c2ed9fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating return code\n",
    "x = feat.merge(pred, on = 'TestId', how = 'left')[['mean_cal', 'mean_post', 'mean_sample', 'cal-post', 'cal-sample', 'sample-post', 'ReturnCode']]\n",
    "y = feat.merge(pred, on = 'TestId', how = 'left')[['Label_x']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c147e39-5891-4137-90b5-4fc7c32eb393",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.replace(np.nan, 'noreturncode', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6481776-6f75-48c2-80fb-e35072f64ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#creating instance of one-hot-encoder\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "#perform one-hot encoding on 'team' column \n",
    "encoder_df = pd.DataFrame(encoder.fit_transform(x[['ReturnCode']]).toarray())\n",
    "\n",
    "#merge one-hot encoded columns back with original DataFrame\n",
    "final_x = x.join(encoder_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30306efe-f60f-454e-8358-af0a24584756",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = final_x.drop(columns = 'ReturnCode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c442e91-bf59-477e-8792-c17cf9e5c25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, stratify = y, random_state = 2022)\n",
    "print(f\"% of ecds in training set: {np.round(np.mean(y_train['Label_x'])*100,3)}\")\n",
    "print(f\"% of ecds in testing set: {np.round(np.mean(y_test['Label_x'])*100,3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c6853d-31f4-49f1-b5ec-f8707b4b23ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49571463-54ef-4d4c-a6f7-e69a9c54b96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets fit a rf with default parameters\n",
    "rf_default = RandomForestClassifier(random_state = 2022)\n",
    "\n",
    "# Define evaluation procedure\n",
    "cv_rf_default = cross_validate(rf_default, X = X_train, y = y_train,scoring = metrics, n_jobs = -1, cv = 5, verbose = 1)\n",
    "\n",
    "pd.DataFrame.from_dict(cv_rf_default).set_axis(['Fold_1', 'Fold_2', 'Fold_3', 'Fold_4', 'Fold_5'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba6a9cf-5677-4aa6-9824-ebb01b7e0a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average of all folds\n",
    "metrics_rf_default = pd.DataFrame.from_dict(cv_rf_default).set_axis(['Fold_1', 'Fold_2', 'Fold_3', 'Fold_4', 'Fold_5'], axis=0).mean(axis = 0)\n",
    "metrics_rf_default = pd.DataFrame(metrics_rf_default).set_axis(['Avg Fit Time', 'Avg Score Time', '5-Fold Balanced Accuracy', '5-Fold Precision', '5-Fold Recall', '5-Fold F1', '5-Fold Log Loss'], axis = 0).T.set_axis(['Random Forest'])\n",
    "metrics_rf_default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58856dd-7ab1-4583-b685-210a2526dcf9",
   "metadata": {},
   "source": [
    "### Evaluating on testing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbab227-8330-4f3b-af71-2d3478987856",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_default = RandomForestClassifier(random_state = 2022)\n",
    "rf_default.fit(X_train, y_train)\n",
    "predictions_rf_tuned = rf_default.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cacc00-4128-4da1-9f44-aac157bbaea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "test_metrics_rf = [metrics.balanced_accuracy_score(y_test, predictions_rf_tuned),\n",
    "                    metrics.precision_score(y_test, predictions_rf_tuned),\n",
    "                    metrics.recall_score(y_test, predictions_rf_tuned),\n",
    "                    metrics.f1_score(y_test, predictions_rf_tuned),\n",
    "                    metrics.log_loss(y_test, predictions_rf_tuned)]\n",
    "overall_performance = pd.DataFrame(test_metrics_rf).T\n",
    "overall_performance.set_axis(['Balanced Accuracy', 'Precision', 'Recall', 'F1 Score', 'Log Loss'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e82cf3-2394-4459-89a5-4f6653cfb2ed",
   "metadata": {},
   "source": [
    "## CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9831282d-aa49-4e6d-8dbc-0a4c7c1ed29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as shc\n",
    "plt.figure(figsize=(5, 5))  \n",
    "plt.title(\"Dendrograms\")  \n",
    "dend = shc.dendrogram(shc.linkage(feat[['cal-post', 'cal-sample', 'sample-post']], method='ward'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efebdff0-b669-4cc9-9143-0e6906fb6bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))  \n",
    "plt.title(\"Dendrograms\")  \n",
    "dend = shc.dendrogram(shc.linkage(feat[['cal-post', 'cal-sample', 'sample-post']], method='single'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5629e2f3-d08d-40a6-ada6-f8fe3b117ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))  \n",
    "plt.title(\"Dendrograms\")  \n",
    "dend = shc.dendrogram(shc.linkage(feat[['cal-post', 'cal-sample', 'sample-post']], method='complete'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c68d16-ada8-4e69-9d9c-f85ed7c7fbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))  \n",
    "plt.title(\"Dendrograms\")  \n",
    "dend = shc.dendrogram(shc.linkage(feat[['cal-post', 'cal-sample', 'sample-post']], method='average'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afab0224-427b-4ec1-912c-e0ebd838cc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# clust_ward_2 = AgglomerativeClustering(n_clusters = 2, affinity='euclidean', linkage='ward')\n",
    "# clust_ward_2.fit_predict(feat[['cal-post', 'cal-sample', 'sample-post']])\n",
    "\n",
    "# clust_ward_3 = AgglomerativeClustering(n_clusters = 3, affinity='euclidean', linkage='ward')\n",
    "# clust_ward_3.fit_predict(feat[['cal-post', 'cal-sample', 'sample-post']])\n",
    "\n",
    "# clust_ward_4 = AgglomerativeClustering(n_clusters = 4, affinity='euclidean', linkage='ward')\n",
    "# clust_ward_4.fit_predict(feat[['cal-post', 'cal-sample', 'sample-post']])\n",
    "\n",
    "# clust_ward_30 = AgglomerativeClustering(n_clusters = 30, affinity='euclidean', linkage='ward')\n",
    "# clust_ward_30.fit_predict(feat[['cal-post', 'cal-sample', 'sample-post']])\n",
    "\n",
    "clust_ward_40 = AgglomerativeClustering(n_clusters = 40, affinity='euclidean', linkage='ward')\n",
    "clust_ward_40.fit_predict(feat[['cal-post', 'cal-sample', 'sample-post']])\n",
    "\n",
    "clust_ward_100 = AgglomerativeClustering(n_clusters = 100, affinity='euclidean', linkage='ward')\n",
    "clust_ward_100.fit_predict(feat[['cal-post', 'cal-sample', 'sample-post']])\n",
    "\n",
    "# clust_single = AgglomerativeClustering(n_clusters = 2, affinity='euclidean', linkage='single')\n",
    "# clust_single.fit_predict(feat[['cal-post', 'cal-sample', 'sample-post']])\n",
    "\n",
    "# clust_complete = AgglomerativeClustering(n_clusters = 2, affinity='euclidean', linkage='complete')\n",
    "# clust_complete.fit_predict(feat[['cal-post', 'cal-sample', 'sample-post']])\n",
    "\n",
    "# clust_average = AgglomerativeClustering(n_clusters = 2, affinity='euclidean', linkage='average')\n",
    "# clust_average.fit_predict(feat[['cal-post', 'cal-sample', 'sample-post']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f03877-d31d-43f7-8929-ef6ef78a1de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat['clust_ward_2'] = clust_ward_2.labels_\n",
    "# feat['clust_ward_3'] = clust_ward_3.labels_\n",
    "# feat['clust_ward_4'] = clust_ward_4.labels_\n",
    "# feat['clust_ward_30'] = clust_ward_30.labels_\n",
    "feat['clust_ward_40'] = clust_ward_40.labels_\n",
    "feat['clust_ward_100'] = clust_ward_100.labels_\n",
    "# feat['clust_single'] = clust_single.labels_\n",
    "# feat['clust_complete'] = clust_complete.labels_\n",
    "# feat['clust_average'] = clust_average.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531ac9d7-c3d7-4d90-b2ac-913826dc6da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4086bb-7e2b-4cb6-a3f3-eed3dda378ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(feat).mark_bar().encode(\n",
    "    alt.X('clust_ward_2'),\n",
    "    alt.Y('count()'),\n",
    "    alt.Color('Label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d016937-fa6c-46b3-9eb2-ec3170c833f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(feat).mark_bar().encode(\n",
    "    alt.X('clust_ward_3'),\n",
    "    alt.Y('count()'),\n",
    "    alt.Color('Label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8142f2d1-55a4-484e-aef8-9f781119cce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(feat).mark_bar().encode(\n",
    "    alt.X('clust_ward_4'),\n",
    "    alt.Y('count()'),\n",
    "    alt.Color('Label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb1c991-8700-44ea-a40f-b39f020ca5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(feat).mark_bar().encode(\n",
    "    alt.X('clust_ward_30'),\n",
    "    alt.Y('count()'),\n",
    "    alt.Color('Label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b918adff-1c3a-43cd-824a-2b530f2a53bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(feat).mark_bar().encode(\n",
    "    alt.X('clust_ward_40'),\n",
    "    alt.Y('count()'),\n",
    "    alt.Color('Label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aac2d68-c74f-4aa5-b93c-0383a8d8b52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(feat).mark_bar().encode(\n",
    "    alt.X('clust_ward_100'),\n",
    "    alt.Y('count()'),\n",
    "    alt.Color('Label'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163a5982-78f1-4695-bf0e-af8a887e8385",
   "metadata": {},
   "source": [
    "## Visualizations of clusters formed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a69a310-f794-4860-b9c5-409f6775f26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictors\n",
    "un_pred = pd.read_csv('../../../data/RawDataPredictors/New/Unsuccessful.csv')\n",
    "ecd_pred = pd.read_csv('../../../data/RawDataPredictors/New/ecdContact.csv')\n",
    "syn_pred = pd.read_csv('../../../data/RawDataPredictors/New/SyntheticECD.csv')\n",
    "con_pred = pd.read_csv('../../../data/RawDataPredictors/New/ECDAggContaminated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a08fc86-cfae-44d9-b2e5-15f60f7bae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecd_pred['Label'] = 'wild'\n",
    "syn_pred['Label'] = 'syn'\n",
    "con_pred['Label'] = 'con'\n",
    "un_pred['Label'] = 'un'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4594088-fc2b-4bea-9a15-ba4f5ee68dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecd_pred_tot = pd.concat([ecd_pred, syn_pred, con_pred])\n",
    "ecd_pred_tot = ecd_pred_tot.rename({'TestID':'TestId'}, axis = 1)\n",
    "\n",
    "un_pred = un_pred.rename({'TestID' : 'TestId'}, axis = 1)\n",
    "\n",
    "pred = pd.concat([un_pred, ecd_pred_tot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e6e7fd-9442-40d0-870b-9efbfb03bb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series (normalized and from -30 to 40)\n",
    "ecd = pd.read_csv(\"../../../data/TimeSeriesData/Normalized/ecd_norm_window.csv\")\n",
    "ecd_syn = pd.read_csv(\"../../../data/TimeSeriesData/Normalized/syn_norm_window.csv\")\n",
    "ecd_con = pd.read_csv(\"../../../data/TimeSeriesData/Normalized/cont_norm_window.csv\")\n",
    "un = pd.read_csv(\"../../../data/TimeSeriesData/Normalized/un_norm_window.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b5b6b4-3116-4125-82d2-e150c39f78ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecd_ts = pd.concat([ecd, ecd_syn, ecd_con])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0916980-14e6-4df8-b0e7-4b5ed40fc73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = pd.concat([ecd_ts, un])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e609a75-0c9b-4ced-a572-47700cae618a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_pred = ts.merge(pred, on = 'TestId', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4242be-1a3f-47b3-ac90-7c6a2da76c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e845dd32-505a-4997-95e0-6d1c3a983f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now join the cluster\n",
    "ts_pred_cluster = ts_pred.merge(feat.drop(columns = 'Label', axis = 1), on = 'TestId', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ff639d-1e66-4e13-9c57-714802f326ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_pred_cluster.ReturnCode = ts_pred_cluster.ReturnCode.astype(str)\n",
    "ts_pred_cluster.FluidType = ts_pred_cluster.FluidType.astype(str)\n",
    "ts_pred_cluster.Label = ts_pred_cluster.Label.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2340877f-09e0-4689-b2b5-e2764df94c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_pred_cluster.iloc[:, 1:351]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1ae118-6279-4a61-9218-e1ccb6ee9114",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'clust_ward_40'\n",
    "for cluster in range(len(ts_pred_cluster[method].unique())):\n",
    "    #for error in combo['ReturnCode'].unique():\n",
    "        #clust_size = sum(combo['Cluster'] == cluster)\n",
    "        #num_error = sum((combo['Cluster'] == cluster) & (combo['ReturnCode'] == error))\n",
    "        #print('Proportion of\\t', error, '\\t\\tin cluster', cluster, 'is\\t', round(num_error/clust_size, 2), '(', num_error, '/', clust_size, ')')\n",
    "    fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize = (20,5))\n",
    "    \n",
    "    ax1.hist(ts_pred_cluster[ts_pred_cluster[method] == cluster]['ReturnCode'], bins = len((ts_pred_cluster[ts_pred_cluster[method] == cluster]['ReturnCode']).unique()))\n",
    "    ax2.hist(ts_pred_cluster[ts_pred_cluster[method] == cluster]['FluidType'], bins = len((ts_pred_cluster[ts_pred_cluster[method] == cluster]['FluidType']).unique()))\n",
    "    ax3.hist(ts_pred_cluster[ts_pred_cluster[method] == cluster]['Label'], bins = len((ts_pred_cluster[ts_pred_cluster[method] == cluster]['Label']).unique()))\n",
    "    ax4.plot(ts_pred_cluster[ts_pred_cluster[method] == cluster].iloc[:, 1:351].transpose())\n",
    "    ax1.tick_params(labelrotation=90)\n",
    "    ax2.tick_params(labelrotation=90)\n",
    "    ax3.tick_params(labelrotation=90)\n",
    "    fig.show()\n",
    "    #print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25817f04-7949-4303-8d76-b24d63ca1598",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
