{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a364b1b-021a-48c4-ab89-1ccffd93dc98",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "This notebook tries to cluster frequency domain of the calibration window of the readings into 2 groups using agglomerative clustering with 3 clusters and with euclidean distance as a distance measure. This process was also repeated after trying to extract features from the frequency domain with TSFresh. ecd contacts were not separated from unsuccessful in either case. Plotting the first two components of a PCA further demonstrated the lack of separation between these two groups.  We also tried this on the post ad sample windows with similar results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916aa6ee-7cd0-4fbf-86a5-05498e698345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tsfresh import extract_features, select_features\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d18d2c-0ffe-4c74-93e3-0438683e54a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These files can be generated by following the preprocessing steps outlined in the glossary. \n",
    "un_ts = pd.read_csv('Data/Windowed Time Series/un_cal.csv')\n",
    "ecd_ts = pd.read_csv('Data/Windowed Time Series/ecd_cal.csv')\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d6d1a0-b15e-4dcc-8ca5-57b6af8b5c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale to get the waveforms as int16 for fft. \n",
    "un_normalized = np.int16([((un_ts.drop('TestId', axis = 1).iloc[i,:] /un_ts.drop('TestId', axis = 1).iloc[i,:].max()) * 32767) for i in range(len(un_ts))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d075e749-31f2-4ceb-9ee9-e864633ca0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fft import rfft, rfftfreq\n",
    "\n",
    "# Number of samples in normalized_tone\n",
    "N = 50\n",
    "\n",
    "un_yf = rfft(un_normalized)\n",
    "xf = rfftfreq(N, 1 / 5)\n",
    "\n",
    "for i in range(7000):\n",
    "    plt.plot(xf, np.abs(un_yf[i,:]))\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0150718-dec7-41bf-99a8-6ed93aae24ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale to get the waveforms as int16 for fft.\n",
    "ecd_normalized = np.int16([((ecd_ts.drop('TestId', axis = 1).iloc[i,:] /ecd_ts.drop('TestId', axis = 1).iloc[i,:].max()) * 32767) for i in range(len(ecd_ts))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935867b3-5403-460a-aae5-959555cc0617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of samples in normalized_tone\n",
    "N = 50\n",
    "\n",
    "ecd_yf = rfft(ecd_normalized)\n",
    "\n",
    "for i in range(200):\n",
    "    plt.plot(xf, np.abs(ecd_yf[i,:]))\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c658073d-c2e1-4958-a1e9-c21e69dbdf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecd_yf = np.abs(ecd_yf)\n",
    "un_yf = np.abs(un_yf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f76bda-cbed-4c8e-b959-e1de3c20f3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecd_lab = pd.Series(['ecd'])\n",
    "un_lab = pd.Series(['un'])\n",
    "x = un_lab.repeat(len(un_ts))\n",
    "y = ecd_lab.repeat(len(ecd_ts))\n",
    "labs = pd.concat([x, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eac5579-44d7-4e54-a732-4a4fee73e181",
   "metadata": {},
   "outputs": [],
   "source": [
    "yf = pd.concat([pd.DataFrame(un_yf, columns = xf), pd.DataFrame(ecd_yf, columns = xf)]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917194ca-f0ef-400c-b631-ae85f843ce28",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(yf)\n",
    "ecda = PCA(n_components=0.95)\n",
    "principalComponents = pca.fit_transform(scaled_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefab8b7-d2ed-40be-b15b-c328779e25c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcadf = pd.DataFrame(data = principalComponents, columns = ['Component '+ str(i+1) for i in range(pca.n_components_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f500701-6fd3-4516-bc69-51b56f4bec91",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcadf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d20f94-f331-4a71-a9d5-af43d37e4996",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = {'ecd':\"red\", 'un':\"blue\"}\n",
    "plt.scatter(pcadf['Component 1'], pcadf['Component 2'], c = labs.map(cmap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a17f28-4684-4c25-95e0-efc06cc4db14",
   "metadata": {},
   "outputs": [],
   "source": [
    "linked = linkage(yf, 'ward')\n",
    "\n",
    "labelList = range(len(yf))\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "dendrogram(linked,\n",
    "            orientation='top',\n",
    "            labels=labelList,\n",
    "            distance_sort='descending',\n",
    "            show_leaf_counts=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb10b8e-20bf-4d59-b28a-f2baa7e8af58",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward')\n",
    "res = cluster.fit_predict(pcadf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a2ed91-679d-49b2-900a-48142344f141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(labels, clusters, ecd, un):\n",
    "    print(\"There are\", str(len(pd.Series(clusters).unique())), \"clusters:\", \"\\n\")\n",
    "    \n",
    "    unl = clusters[labels == 'un']\n",
    "    ecdl = clusters[labels == 'ecd']\n",
    "    for i in range(len(pd.Series(clusters).unique())):\n",
    "        print(\"Cluster\",  str(i+1), \":\")\n",
    "        print(\"-----------------------------------\")\n",
    "        print(str(sum(ecdl == i)), \"of\", str(ecd), \"ecd contacts\", '\\t', round(sum(ecdl == i)/ecd*100, 2), '%')\n",
    "        print(str(sum(unl == i)), \"of\", str(un), \"unsuccessful\", '\\t', round(sum(unl == i)/un*100, 2), '%')\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8483510e-ee60-4f6c-9918-6fdced45c11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results(labs, res, len(ecd_ts), len(un_ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5067d4a5-3331-4759-860e-91165d36a1ae",
   "metadata": {},
   "source": [
    "# What about feature extraction then clustering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd76ea75-480f-4988-99fe-a217f256619d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c6982b-4519-4fbe-8718-a9194bd5ea2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([un_ts['TestId'], ecd_ts['TestId']]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2beb42-a516-4b38-b5ec-ce41618959c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "yf['TestId'] = pd.concat([un_ts['TestId'], ecd_ts['TestId']]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c727df79-f462-457f-ae87-f89264c5c29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811d4539-6f17-4b49-89f8-6cb1f5525aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "melt_data = pd.melt(yf, id_vars = 'TestId', var_name = 'time')\n",
    "melt_data['time'] = pd.to_numeric(melt_data['time'])\n",
    "melt_data = melt_data.sort_values(by = ['TestId', 'time']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe11068-dd42-4043-9391-347791114a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "melt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fa0f25-5ed8-468c-a56d-4edf6286998c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to extract features seperately for all ids\n",
    "extracted_features = extract_features(melt_data, column_id=\"TestId\", column_sort=\"time\", column_value = 'value')\n",
    "# Remove all features containing NaN values (which were created because could not be calculated on the time series, i.e. stat too low)\n",
    "extracted_features.dropna(axis='columns', inplace = True)\n",
    "\n",
    "# Select the relevant features\n",
    "impute(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f349b448-7ac2-4f29-a1c9-4231bbcc3c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the feature matrix\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(extracted_features)\n",
    "\n",
    "print(f\"The total number of features created is: {len(extracted_features.columns)}\")\n",
    "\n",
    "\n",
    "#Convert to data frame with test ids as index and appropriate column labels\n",
    "scaled_features  = pd.DataFrame(scaled_features, columns = extracted_features.columns).set_index(extracted_features.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5aa672-5926-4f9b-8c52-217d5ac52b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.95)\n",
    "principalComponents = pca.fit_transform(scaled_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1d37a7-6f23-4e2e-8b19-0058667fa0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcadf = pd.DataFrame(data = principalComponents, columns = ['Component '+ str(i+1) for i in range(pca.n_components_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591b7dcb-ba43-4301-9848-7c4446591772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "gmm = GaussianMixture(n_components = 2).fit(pcadf)\n",
    "clusters = gmm.predict(pcadf)\n",
    "results(labs, clusters, len(ecd_ts), len(un_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5534fe29-30dd-41fe-8b51-e3df6e0dad77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f288678-2e09-4c70-b461-a5871aad92e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
