{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36f79d40-8d20-4a1e-91c2-e956635aeda1",
   "metadata": {},
   "source": [
    "# **SOM Notebook Description**\n",
    "\n",
    "This notebook uses a self organizing map (SOM) to try and cluster the waveforms after subsetting from 30 seconds before sample detect to 40 seconds after sample detect, then normalizing the waveforms between 0 and 1, and then using a convolution smoother. The most important features according to the random forest are used as additional predictors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc90d841",
   "metadata": {},
   "source": [
    "## **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473ca729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd            \n",
    "import numpy as np           \n",
    "import matplotlib.pyplot as plt                                          \n",
    "# import package used for SOM algorithm\n",
    "from minisom import MiniSom\n",
    "# import in-house diagnostic functions\n",
    "from diagnostics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bc5d95-c0c2-49e0-bbeb-29b42738812d",
   "metadata": {},
   "source": [
    "## **Read in the Preprocessed Data that is to be Clustered**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bf05db-7209-4221-a4f6-947fb3ac862e",
   "metadata": {},
   "source": [
    "## Load the smoothed time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80d445c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecd_ts = pd.read_csv('../Data/PreprocessedData/TimeSeries/ecd_smooth.csv')            \n",
    "syn_ts = pd.read_csv('../Data/PreprocessedData/TimeSeries/syn_smooth.csv')               \n",
    "cont_ts = pd.read_csv('../Data/PreprocessedData/TimeSeries/cont_smooth.csv')       \n",
    "un_ts = pd.read_csv('../Data/PreprocessedData/TimeSeries/un_smooth.csv')                \n",
    "\n",
    "# Make a new data frame with all of the different kinds of ECDs. \n",
    "allecd_ts = pd.concat([ecd_ts, cont_ts, syn_ts])\n",
    "# Make a data frame with all of the waveforms together. \n",
    "all_ts = pd.concat([un_ts, allecd_ts]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13ed7cd-c685-43cd-9786-d901c6e78d4a",
   "metadata": {},
   "source": [
    "## Load the predictor files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad929ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "un_pred =  pd.read_csv('../Data/PreprocessedData/Predictors/Unsuccessful.csv')\n",
    "ecd_pred =  pd.read_csv('../Data/PreprocessedData/Predictors/ECD.csv')\n",
    "syn_pred =  pd.read_csv('../Data/RawData/Predictors/SyntheticPC.csv')\n",
    "con_pred =  pd.read_csv('../Data/RawData/Predictors/PCAggContaminated.csv')\n",
    "\n",
    "# Make a new data frame with all of the predictors. \n",
    "all_preds = pd.concat([un_pred, ecd_pred, syn_pred, con_pred])\n",
    "# Rename TestID to TestId to match the time series data. \n",
    "all_preds = all_preds.rename({'TestID':'TestId'}, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746fb4ad-963f-42e7-a789-3810f496e78b",
   "metadata": {},
   "source": [
    "## Make a list of the most important features according to random forest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384ed9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset of predictors data containing most important features according to random forest. \n",
    "preds_subset=all_preds[['TestId','CExtrapolation', \\\n",
    "             'CDrift', 'CNoise', 'CSecond',\\\n",
    "             'CWindowMovedBack', 'SDrift', \\\n",
    "             'SNoise', 'PSecond', 'TransDrift','AFirst']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fe46a1-d6a0-4d6f-94ab-a77513d0caf9",
   "metadata": {},
   "source": [
    "## Make a new dataframe combining the time series and important features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28789d3e-4fd7-4ebf-baf3-090e2146305b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ts_and_preds = all_ts.merge(preds_subset, on = 'TestId', how = 'left')\n",
    "all_ts_and_preds = all_ts_and_preds.drop('TestId', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed1d7be-7775-40f1-b09b-da0e5b3f30f6",
   "metadata": {},
   "source": [
    "Create the labels for the different kinds of readings and store them for future use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648be48b-f1aa-4b72-a600-1767679d0b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the labels. \n",
    "un_lab = pd.Series(['un']).repeat(len(un_ts))\n",
    "ecd_lab = pd.Series(['pc']).repeat(len(allecd_ts))\n",
    "wild_lab = pd.Series(['wild']).repeat(len(ecd_ts))\n",
    "cont_lab = pd.Series(['cont']).repeat(len(cont_ts))\n",
    "syn_lab = pd.Series(['synth']).repeat(len(syn_ts))\n",
    "\n",
    "# Store labels for all the categories (pc, cont, syn, and un)\n",
    "labs = pd.concat([un_lab, wild_lab, cont_lab, syn_lab]).reset_index(drop = True)\n",
    "                                      \n",
    "# Save a copy of ids for future use. \n",
    "ids = all_ts['TestId']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8803ed5",
   "metadata": {},
   "source": [
    "## **Functions to Create Self organizing maps**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cb0169",
   "metadata": {},
   "source": [
    "There are two functions defined: <br>\n",
    "- minisom_func: The actual algorithm of minisom and clustering\n",
    "- clutser_map : The function to convert maps to clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20da92f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minisom_func(ts_list,som_x,som_y,sigma,activation_distance,learning_rate,epochs,neighborhood_function):\n",
    "    \"\"\" The minisom function for finding clusters. This function and the docstring are heavily copied from the original package\n",
    "        (https://github.com/JustGlowing/minisom/blob/master/minisom.py)\n",
    "       \n",
    "        Parameters\n",
    "        ----------\n",
    "        ts_list : list\n",
    "            The dataframe (converted to list for minisom package) containing the data to cluster\n",
    "        som_x : int\n",
    "            x dimension of the SOM.\n",
    "        som_y : int\n",
    "            y dimension of the SOM.\n",
    "        sigma : float, optional (default=1.0)\n",
    "            Spread of the neighborhood function, needs to be adequate\n",
    "            to the dimensions of the map.\n",
    "            (at the iteration t we have sigma(t) = sigma / (1 + t/T)\n",
    "            where T is #num_iteration/2)\n",
    "        activation_distance : string, callable optional (default='euclidean')\n",
    "            Distance used to activate the map.\n",
    "            Possible values: 'euclidean', 'cosine', 'manhattan', 'chebyshev'\n",
    "            Example of callable that can be passed:\n",
    "            def euclidean(x, w):\n",
    "                return linalg.norm(subtract(x, w), axis=-1)\n",
    "        learning_rate : initial learning rate\n",
    "            (at the iteration t we have\n",
    "            learning_rate(t) = learning_rate / (1 + t/T)\n",
    "            where T is #num_iteration/2)\n",
    "        neighborhood_function : string, optional (default='gaussian')\n",
    "            Function that weights the neighborhood of a position in the map.\n",
    "            Possible values: 'gaussian', 'mexican_hat', 'bubble', 'triangle'\n",
    "    \n",
    "        Returns : som object\n",
    "        \"\"\"\n",
    "    # initializing minisom\n",
    "    som = MiniSom(som_x,som_y,len(ts_list[0]),sigma=sigma,\\\n",
    "                  learning_rate=learning_rate,activation_distance=activation_distance,\\\n",
    "                  neighborhood_function=neighborhood_function,random_seed=30)             \n",
    "    \n",
    "    # initializing random weights \n",
    "    som.random_weights_init(ts_list)                                                                                 \n",
    "    \n",
    "     # Training minisom\n",
    "    print(\"Training minisom function\")\n",
    "    som.train_random(ts_list,epochs)                                                     \n",
    "    print(\"\\n...maps are ready!\")\n",
    "\n",
    "    return som"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdca9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cluster_map(ts_list,parameters):\n",
    "    \"\"\" Function to define the clusters in SOM and distribution of clusters in different waveforms\n",
    "       \n",
    "        Parameters\n",
    "        ----------\n",
    "        ts_list : list\n",
    "            The dataframe (converted to list for minisom package) containing the data to cluster\n",
    "        parameters : dict\n",
    "            dictionary of parameters that go into the minisom_func\n",
    "        Returns : list\n",
    "            a list with the cluster labels produced by the SOM. \n",
    "        \"\"\"\n",
    "    # calling minisom function\n",
    "    som=minisom_func(ts_list,parameters['som_x'],parameters['som_y'],\\\n",
    "                     parameters['sigma'],parameters['activation_distance'],\\\n",
    "                     parameters['learning_rate'],parameters['epochs'],parameters['neighborhood_function'])\n",
    "    # Obtaining maps for each data point\n",
    "    win_map=som.win_map(ts_list)                            \n",
    "    \n",
    "    # list to obtain clusters\n",
    "    cluster_c = []  \n",
    "    # list to obtain count in each cluster\n",
    "    cluster_n = []                                          \n",
    "    \n",
    "    # loop to populate clusters and their counts.\n",
    "    for x in range(parameters['som_x']):                    \n",
    "        for y in range(parameters['som_y']):\n",
    "            cluster = (x,y)\n",
    "            if cluster in win_map.keys():\n",
    "                cluster_c.append(len(win_map[cluster]))\n",
    "            else:\n",
    "                cluster_c.append(0)\n",
    "            cluster_number = x*parameters['som_y']+y+1\n",
    "            cluster_n.append(f\"Cluster {cluster_number}\")\n",
    "    \n",
    "\n",
    "\n",
    "    # Create a list associating each data point to its cluster.\n",
    "    cluster_map = []                                       \n",
    "    for idx in range(len(ts_list)):\n",
    "        winner_node = som.winner(ts_list[idx])\n",
    "        cluster_number=winner_node[0]*parameters['som_y']+winner_node[1]+1\n",
    "        cluster_map.append(cluster_number)\n",
    "\n",
    "    # Return the list that labels each data point with it's assigned cluster. \n",
    "    return cluster_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6688783b-04db-4a25-b561-bea099e3bea0",
   "metadata": {},
   "source": [
    "## **Run SOM Clustering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4c0c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the parameters for minisom function.\n",
    "# Product of som_x and som_y are the number of clusters that will be produced. \n",
    "parameters={'som_x':15,'som_y':2,'sigma':0.7,'activation_distance':'manhattan',\\\n",
    "            'learning_rate':0.01,'epochs':5000,'neighborhood_function':'gaussian'}\n",
    "\n",
    "# Convert the dataframe to  a list for SOM. \n",
    "ts_list = all_ts_and_preds.values.tolist()\n",
    "\n",
    "# Get the clusters according to the minisom algorithm\n",
    "y_pred = create_cluster_map(ts_list = ts_list, parameters = parameters)                                      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7bde00-58fe-454c-b5bb-e58d1a80f17d",
   "metadata": {},
   "source": [
    "##  **Do some diagnostics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c29e662-c76a-432d-a8ff-50766dfb7b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define start and end times for plotting. \n",
    "start = -30\n",
    "end = 39.8\n",
    "# Get the data ito correct format for diagnostics. \n",
    "ts_pred = prepare_data(all_ts, all_preds, clusters = y_pred, labels = labs)\n",
    "# Plot some info about the clusters. \n",
    "describe_clusters(ts_pred, ['ReturnCode', 'AggPred1', 'AggPred2'], start = start, end = end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bcac17-722b-48c0-b86e-09ddf41eb816",
   "metadata": {},
   "source": [
    "If we just want a quick data frame to see which clusters have most of the ECDs, we can call the following function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db769b2c-9944-4764-80a3-2d1383b503de",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_label_counts(ts_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866148db-fdaf-4143-8c46-3c374a46db36",
   "metadata": {},
   "source": [
    "If we are interested in comparing the distributions of certain aggregate predictors we can also do that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3f6461-c586-48fe-bc45-7cde9d0ecc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_cluster_densities(ts_pred, clust1 = 12, clust2 = 16, \n",
    "                          feature_list = ['AggPred1', 'AggPred2', 'AggPred3'], clust_col = 'Cluster')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d054f2d-2a0a-4415-b70e-dc023f82070d",
   "metadata": {},
   "source": [
    "Here it looks like these two clusters have a lot of overlap on these predictors. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
